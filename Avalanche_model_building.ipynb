{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe from the avalanche records\n",
    "avalanche_df = pd.read_csv('data/avalanche.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe from the list of stations.\n",
    "station_df = pd.read_csv('Data\\Station Inventory EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2450, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "avalanche_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8775, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "station_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                    location                   date_occured\n",
       "0           0  59.713938° N 135.095702° W  Thursday, May 27, 2021, 14:00\n",
       "1           1  51.171303° N 116.051255° W  Saturday, May 22, 2021, 09:00\n",
       "2           2  50.427560° N 122.473110° W    Sunday, May 16, 2021, 11:00\n",
       "3           3  51.394930° N 116.265450° W  Saturday, May 15, 2021, 12:00\n",
       "4           4  51.395059° N 116.257463° W    Friday, May 14, 2021, 12:30"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>location</th>\n      <th>date_occured</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938° N 135.095702° W</td>\n      <td>Thursday, May 27, 2021, 14:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303° N 116.051255° W</td>\n      <td>Saturday, May 22, 2021, 09:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560° N 122.473110° W</td>\n      <td>Sunday, May 16, 2021, 11:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930° N 116.265450° W</td>\n      <td>Saturday, May 15, 2021, 12:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059° N 116.257463° W</td>\n      <td>Friday, May 14, 2021, 12:30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "avalanche_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     Name          Province Climate ID  Station ID  WMO ID  \\\n",
       "0             ACTIVE PASS  BRITISH COLUMBIA    1010066          14     NaN   \n",
       "1             ALBERT HEAD  BRITISH COLUMBIA    1010235          15     NaN   \n",
       "2  BAMBERTON OCEAN CEMENT  BRITISH COLUMBIA    1010595          16     NaN   \n",
       "3              BEAR CREEK  BRITISH COLUMBIA    1010720          17     NaN   \n",
       "4             BEAVER LAKE  BRITISH COLUMBIA    1010774          18     NaN   \n",
       "\n",
       "  TC ID  Latitude (Decimal Degrees)  Longitude (Decimal Degrees)   Latitude  \\\n",
       "0   NaN                       48.87                      -123.28  485200000   \n",
       "1   NaN                       48.40                      -123.48  482400000   \n",
       "2   NaN                       48.58                      -123.52  483500000   \n",
       "3   NaN                       48.50                      -124.00  483000000   \n",
       "4   NaN                       48.50                      -123.35  483000000   \n",
       "\n",
       "    Longitude  Elevation (m)  First Year  Last Year  HLY First Year  \\\n",
       "0 -1231700000            4.0        1984       1996             NaN   \n",
       "1 -1232900000           17.0        1971       1995             NaN   \n",
       "2 -1233100000           85.3        1961       1980             NaN   \n",
       "3 -1240000000          350.5        1910       1971             NaN   \n",
       "4 -1232100000           61.0        1894       1952             NaN   \n",
       "\n",
       "   HLY Last Year  DLY First Year  DLY Last Year  MLY First Year  MLY Last Year  \n",
       "0            NaN          1984.0         1996.0          1984.0         1996.0  \n",
       "1            NaN          1971.0         1995.0          1971.0         1995.0  \n",
       "2            NaN          1961.0         1980.0          1961.0         1980.0  \n",
       "3            NaN          1910.0         1971.0          1910.0         1971.0  \n",
       "4            NaN          1894.0         1952.0          1894.0         1952.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>WMO ID</th>\n      <th>TC ID</th>\n      <th>Latitude (Decimal Degrees)</th>\n      <th>Longitude (Decimal Degrees)</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Elevation (m)</th>\n      <th>First Year</th>\n      <th>Last Year</th>\n      <th>HLY First Year</th>\n      <th>HLY Last Year</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>MLY First Year</th>\n      <th>MLY Last Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ACTIVE PASS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1010066</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.87</td>\n      <td>-123.28</td>\n      <td>485200000</td>\n      <td>-1231700000</td>\n      <td>4.0</td>\n      <td>1984</td>\n      <td>1996</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1984.0</td>\n      <td>1996.0</td>\n      <td>1984.0</td>\n      <td>1996.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ALBERT HEAD</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1010235</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.40</td>\n      <td>-123.48</td>\n      <td>482400000</td>\n      <td>-1232900000</td>\n      <td>17.0</td>\n      <td>1971</td>\n      <td>1995</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1971.0</td>\n      <td>1995.0</td>\n      <td>1971.0</td>\n      <td>1995.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BAMBERTON OCEAN CEMENT</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1010595</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.58</td>\n      <td>-123.52</td>\n      <td>483500000</td>\n      <td>-1233100000</td>\n      <td>85.3</td>\n      <td>1961</td>\n      <td>1980</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1961.0</td>\n      <td>1980.0</td>\n      <td>1961.0</td>\n      <td>1980.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BEAR CREEK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1010720</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.50</td>\n      <td>-124.00</td>\n      <td>483000000</td>\n      <td>-1240000000</td>\n      <td>350.5</td>\n      <td>1910</td>\n      <td>1971</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1910.0</td>\n      <td>1971.0</td>\n      <td>1910.0</td>\n      <td>1971.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BEAVER LAKE</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1010774</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.50</td>\n      <td>-123.35</td>\n      <td>483000000</td>\n      <td>-1232100000</td>\n      <td>61.0</td>\n      <td>1894</td>\n      <td>1952</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1894.0</td>\n      <td>1952.0</td>\n      <td>1894.0</td>\n      <td>1952.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from station that had daily reports from 2016-2021\n",
    "station_2016_df = station_df[(station_df['DLY Last Year'] >= 2020) & (station_df['DLY First Year'] <= 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Name          Province Climate ID  Station ID   WMO ID TC ID  \\\n",
       "12          CHEMAINUS  BRITISH COLUMBIA    1011500          26      NaN   NaN   \n",
       "26      LAKE COWICHAN  BRITISH COLUMBIA    1012055          40      NaN   NaN   \n",
       "28   DISCOVERY ISLAND  BRITISH COLUMBIA    1012475       27226  71031.0   WDR   \n",
       "39  ESQUIMALT HARBOUR  BRITISH COLUMBIA    1012710          52  71798.0   WPF   \n",
       "44      GALIANO NORTH  BRITISH COLUMBIA    10130MN          55      NaN   NaN   \n",
       "\n",
       "    Latitude (Decimal Degrees)  Longitude (Decimal Degrees)   Latitude  \\\n",
       "12                       48.94                      -123.74  485606080   \n",
       "26                       48.83                      -124.05  484946000   \n",
       "28                       48.42                      -123.23  482528590   \n",
       "39                       48.43                      -123.44  482555100   \n",
       "44                       48.99                      -123.57  485906030   \n",
       "\n",
       "     Longitude  Elevation (m)  First Year  Last Year  HLY First Year  \\\n",
       "12 -1234430000          75.00        1919       2021             NaN   \n",
       "26 -1240308000         171.00        1960       2021             NaN   \n",
       "28 -1231332519          18.93        1997       2021          1997.0   \n",
       "39 -1232621600           3.00        1957       2021          1994.0   \n",
       "44 -1233424020           6.00        1975       2021             NaN   \n",
       "\n",
       "    HLY Last Year  DLY First Year  DLY Last Year  MLY First Year  \\\n",
       "12            NaN          1919.0         2021.0          1919.0   \n",
       "26            NaN          1960.0         2021.0          1960.0   \n",
       "28         2021.0          1997.0         2021.0          1998.0   \n",
       "39         2021.0          1957.0         2021.0          1957.0   \n",
       "44            NaN          1975.0         2021.0          1975.0   \n",
       "\n",
       "    MLY Last Year  \n",
       "12         2007.0  \n",
       "26         2007.0  \n",
       "28         2005.0  \n",
       "39         2005.0  \n",
       "44         2007.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>WMO ID</th>\n      <th>TC ID</th>\n      <th>Latitude (Decimal Degrees)</th>\n      <th>Longitude (Decimal Degrees)</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Elevation (m)</th>\n      <th>First Year</th>\n      <th>Last Year</th>\n      <th>HLY First Year</th>\n      <th>HLY Last Year</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>MLY First Year</th>\n      <th>MLY Last Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>CHEMAINUS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1011500</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.94</td>\n      <td>-123.74</td>\n      <td>485606080</td>\n      <td>-1234430000</td>\n      <td>75.00</td>\n      <td>1919</td>\n      <td>2021</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1919.0</td>\n      <td>2021.0</td>\n      <td>1919.0</td>\n      <td>2007.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LAKE COWICHAN</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012055</td>\n      <td>40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.83</td>\n      <td>-124.05</td>\n      <td>484946000</td>\n      <td>-1240308000</td>\n      <td>171.00</td>\n      <td>1960</td>\n      <td>2021</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1960.0</td>\n      <td>2021.0</td>\n      <td>1960.0</td>\n      <td>2007.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DISCOVERY ISLAND</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012475</td>\n      <td>27226</td>\n      <td>71031.0</td>\n      <td>WDR</td>\n      <td>48.42</td>\n      <td>-123.23</td>\n      <td>482528590</td>\n      <td>-1231332519</td>\n      <td>18.93</td>\n      <td>1997</td>\n      <td>2021</td>\n      <td>1997.0</td>\n      <td>2021.0</td>\n      <td>1997.0</td>\n      <td>2021.0</td>\n      <td>1998.0</td>\n      <td>2005.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ESQUIMALT HARBOUR</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012710</td>\n      <td>52</td>\n      <td>71798.0</td>\n      <td>WPF</td>\n      <td>48.43</td>\n      <td>-123.44</td>\n      <td>482555100</td>\n      <td>-1232621600</td>\n      <td>3.00</td>\n      <td>1957</td>\n      <td>2021</td>\n      <td>1994.0</td>\n      <td>2021.0</td>\n      <td>1957.0</td>\n      <td>2021.0</td>\n      <td>1957.0</td>\n      <td>2005.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>GALIANO NORTH</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>10130MN</td>\n      <td>55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48.99</td>\n      <td>-123.57</td>\n      <td>485906030</td>\n      <td>-1233424020</td>\n      <td>6.00</td>\n      <td>1975</td>\n      <td>2021</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1975.0</td>\n      <td>2021.0</td>\n      <td>1975.0</td>\n      <td>2007.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "station_2016_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1193 entries, 12 to 8769\nData columns (total 19 columns):\n #   Column                       Non-Null Count  Dtype  \n---  ------                       --------------  -----  \n 0   Name                         1193 non-null   object \n 1   Province                     1193 non-null   object \n 2   Climate ID                   1193 non-null   object \n 3   Station ID                   1193 non-null   int64  \n 4   WMO ID                       832 non-null    float64\n 5   TC ID                        864 non-null    object \n 6   Latitude (Decimal Degrees)   1193 non-null   float64\n 7   Longitude (Decimal Degrees)  1193 non-null   float64\n 8   Latitude                     1193 non-null   int64  \n 9   Longitude                    1193 non-null   int64  \n 10  Elevation (m)                1193 non-null   float64\n 11  First Year                   1193 non-null   int64  \n 12  Last Year                    1193 non-null   int64  \n 13  HLY First Year               867 non-null    float64\n 14  HLY Last Year                867 non-null    float64\n 15  DLY First Year               1193 non-null   float64\n 16  DLY Last Year                1193 non-null   float64\n 17  MLY First Year               818 non-null    float64\n 18  MLY Last Year                818 non-null    float64\ndtypes: float64(10), int64(5), object(4)\nmemory usage: 186.4+ KB\n"
     ]
    }
   ],
   "source": [
    "station_2016_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an array of the location column split up\n",
    "locations = avalanche_df['location'].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds latitude and longitude to the dataframe \n",
    "avalanche_df['latitude'] = locations[0]\n",
    "avalanche_df['longitude'] = locations[2]\n",
    "avalanche_df.drop('location', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the unneeded columns from the dataset\n",
    "columns_to_drop = ['WMO ID','TC ID','Elevation (m)','HLY First Year','HLY Last Year','First Year','Last Year','MLY First Year','MLY Last Year']\n",
    "station_2016_df.drop(columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Name          Province Climate ID  Station ID  \\\n",
       "12            CHEMAINUS  BRITISH COLUMBIA    1011500          26   \n",
       "26        LAKE COWICHAN  BRITISH COLUMBIA    1012055          40   \n",
       "28     DISCOVERY ISLAND  BRITISH COLUMBIA    1012475       27226   \n",
       "39    ESQUIMALT HARBOUR  BRITISH COLUMBIA    1012710          52   \n",
       "44        GALIANO NORTH  BRITISH COLUMBIA    10130MN          55   \n",
       "...                 ...               ...        ...         ...   \n",
       "8735     HOPEDALE (AUT)      NEWFOUNDLAND    8502400        6781   \n",
       "8742   MARY'S HARBOUR A      NEWFOUNDLAND    8502592       51918   \n",
       "8746               NAIN      NEWFOUNDLAND    8502799       10813   \n",
       "8760             SAGLEK      NEWFOUNDLAND    8503249        6797   \n",
       "8769           WABUSH A      NEWFOUNDLAND    8504177       52541   \n",
       "\n",
       "      Latitude (Decimal Degrees)  Longitude (Decimal Degrees)   Latitude  \\\n",
       "12                         48.94                      -123.74  485606080   \n",
       "26                         48.83                      -124.05  484946000   \n",
       "28                         48.42                      -123.23  482528590   \n",
       "39                         48.43                      -123.44  482555100   \n",
       "44                         48.99                      -123.57  485906030   \n",
       "...                          ...                          ...        ...   \n",
       "8735                       55.45                       -60.22  552700000   \n",
       "8742                       52.30                       -55.85  521810000   \n",
       "8746                       56.55                       -61.68  563300000   \n",
       "8760                       58.33                       -62.59  582000000   \n",
       "8769                       52.92                       -66.86  525522000   \n",
       "\n",
       "       Longitude  DLY First Year  DLY Last Year  \n",
       "12   -1234430000          1919.0         2021.0  \n",
       "26   -1240308000          1960.0         2021.0  \n",
       "28   -1231332519          1997.0         2021.0  \n",
       "39   -1232621600          1957.0         2021.0  \n",
       "44   -1233424020          1975.0         2021.0  \n",
       "...          ...             ...            ...  \n",
       "8735  -601300000          1942.0         2021.0  \n",
       "8742  -555052000          2013.0         2021.0  \n",
       "8746  -614100000          2004.0         2020.0  \n",
       "8760  -623508000          1989.0         2021.0  \n",
       "8769  -665153000          2014.0         2021.0  \n",
       "\n",
       "[1193 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>Latitude (Decimal Degrees)</th>\n      <th>Longitude (Decimal Degrees)</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>CHEMAINUS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1011500</td>\n      <td>26</td>\n      <td>48.94</td>\n      <td>-123.74</td>\n      <td>485606080</td>\n      <td>-1234430000</td>\n      <td>1919.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LAKE COWICHAN</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012055</td>\n      <td>40</td>\n      <td>48.83</td>\n      <td>-124.05</td>\n      <td>484946000</td>\n      <td>-1240308000</td>\n      <td>1960.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DISCOVERY ISLAND</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012475</td>\n      <td>27226</td>\n      <td>48.42</td>\n      <td>-123.23</td>\n      <td>482528590</td>\n      <td>-1231332519</td>\n      <td>1997.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ESQUIMALT HARBOUR</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012710</td>\n      <td>52</td>\n      <td>48.43</td>\n      <td>-123.44</td>\n      <td>482555100</td>\n      <td>-1232621600</td>\n      <td>1957.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>GALIANO NORTH</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>10130MN</td>\n      <td>55</td>\n      <td>48.99</td>\n      <td>-123.57</td>\n      <td>485906030</td>\n      <td>-1233424020</td>\n      <td>1975.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8735</th>\n      <td>HOPEDALE (AUT)</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502400</td>\n      <td>6781</td>\n      <td>55.45</td>\n      <td>-60.22</td>\n      <td>552700000</td>\n      <td>-601300000</td>\n      <td>1942.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>8742</th>\n      <td>MARY'S HARBOUR A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502592</td>\n      <td>51918</td>\n      <td>52.30</td>\n      <td>-55.85</td>\n      <td>521810000</td>\n      <td>-555052000</td>\n      <td>2013.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>8746</th>\n      <td>NAIN</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502799</td>\n      <td>10813</td>\n      <td>56.55</td>\n      <td>-61.68</td>\n      <td>563300000</td>\n      <td>-614100000</td>\n      <td>2004.0</td>\n      <td>2020.0</td>\n    </tr>\n    <tr>\n      <th>8760</th>\n      <td>SAGLEK</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8503249</td>\n      <td>6797</td>\n      <td>58.33</td>\n      <td>-62.59</td>\n      <td>582000000</td>\n      <td>-623508000</td>\n      <td>1989.0</td>\n      <td>2021.0</td>\n    </tr>\n    <tr>\n      <th>8769</th>\n      <td>WABUSH A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8504177</td>\n      <td>52541</td>\n      <td>52.92</td>\n      <td>-66.86</td>\n      <td>525522000</td>\n      <td>-665153000</td>\n      <td>2014.0</td>\n      <td>2021.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1193 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "station_2016_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                   date_occured    latitude    longitude\n",
       "0           0  Thursday, May 27, 2021, 14:00  59.713938°  135.095702°\n",
       "1           1  Saturday, May 22, 2021, 09:00  51.171303°  116.051255°\n",
       "2           2    Sunday, May 16, 2021, 11:00  50.427560°  122.473110°\n",
       "3           3  Saturday, May 15, 2021, 12:00  51.394930°  116.265450°\n",
       "4           4    Friday, May 14, 2021, 12:30  51.395059°  116.257463°"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date_occured</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Thursday, May 27, 2021, 14:00</td>\n      <td>59.713938°</td>\n      <td>135.095702°</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Saturday, May 22, 2021, 09:00</td>\n      <td>51.171303°</td>\n      <td>116.051255°</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Sunday, May 16, 2021, 11:00</td>\n      <td>50.427560°</td>\n      <td>122.473110°</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Saturday, May 15, 2021, 12:00</td>\n      <td>51.394930°</td>\n      <td>116.265450°</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Friday, May 14, 2021, 12:30</td>\n      <td>51.395059°</td>\n      <td>116.257463°</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "avalanche_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the degree symbol from latitude and longitude\n",
    "avalanche_df['latitude'] = avalanche_df['latitude'].map(lambda x: str(x)[:-1])\n",
    "avalanche_df['longitude'] = avalanche_df['longitude'].map(lambda x: str(x)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = avalanche_df['date_occured'].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanche_df['weekday'] = dates[0].map(lambda x: str(x)[:-1])\n",
    "avalanche_df['month'] = dates[1]\n",
    "avalanche_df['day'] = dates[2].map(lambda x: str(x)[:-1])\n",
    "avalanche_df['year'] = dates[3].map(lambda x: str(x)[:-1])\n",
    "avalanche_df['time'] = dates[4]\n",
    "avalanche_df.drop('date_occured', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_avalanche = gpd.GeoDataFrame(\n",
    "    avalanche_df, geometry=gpd.points_from_xy(avalanche_df.longitude, avalanche_df.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1193 entries, 12 to 8769\nData columns (total 10 columns):\n #   Column                       Non-Null Count  Dtype  \n---  ------                       --------------  -----  \n 0   Name                         1193 non-null   object \n 1   Province                     1193 non-null   object \n 2   Climate ID                   1193 non-null   object \n 3   Station ID                   1193 non-null   int64  \n 4   Latitude (Decimal Degrees)   1193 non-null   float64\n 5   Longitude (Decimal Degrees)  1193 non-null   float64\n 6   Latitude                     1193 non-null   int64  \n 7   Longitude                    1193 non-null   int64  \n 8   DLY First Year               1193 non-null   float64\n 9   DLY Last Year                1193 non-null   float64\ndtypes: float64(4), int64(3), object(3)\nmemory usage: 102.5+ KB\n"
     ]
    }
   ],
   "source": [
    "station_2016_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_2016_df.rename(columns = {'Latitude (Decimal Degrees)':'latitude', \n",
    "                                  'Longitude (Decimal Degrees)':'longitude'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the negative symbol from longitude\n",
    "station_2016_df['longitude'] = station_2016_df['longitude'].map(lambda x: str(x)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_station = gpd.GeoDataFrame(\n",
    "    station_2016_df, geometry=gpd.points_from_xy(station_2016_df.longitude, station_2016_df.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Name          Province Climate ID  Station ID  latitude  \\\n",
       "12            CHEMAINUS  BRITISH COLUMBIA    1011500          26     48.94   \n",
       "26        LAKE COWICHAN  BRITISH COLUMBIA    1012055          40     48.83   \n",
       "28     DISCOVERY ISLAND  BRITISH COLUMBIA    1012475       27226     48.42   \n",
       "39    ESQUIMALT HARBOUR  BRITISH COLUMBIA    1012710          52     48.43   \n",
       "44        GALIANO NORTH  BRITISH COLUMBIA    10130MN          55     48.99   \n",
       "...                 ...               ...        ...         ...       ...   \n",
       "8735     HOPEDALE (AUT)      NEWFOUNDLAND    8502400        6781     55.45   \n",
       "8742   MARY'S HARBOUR A      NEWFOUNDLAND    8502592       51918     52.30   \n",
       "8746               NAIN      NEWFOUNDLAND    8502799       10813     56.55   \n",
       "8760             SAGLEK      NEWFOUNDLAND    8503249        6797     58.33   \n",
       "8769           WABUSH A      NEWFOUNDLAND    8504177       52541     52.92   \n",
       "\n",
       "     longitude   Latitude   Longitude  DLY First Year  DLY Last Year  \\\n",
       "12      123.74  485606080 -1234430000          1919.0         2021.0   \n",
       "26      124.05  484946000 -1240308000          1960.0         2021.0   \n",
       "28      123.23  482528590 -1231332519          1997.0         2021.0   \n",
       "39      123.44  482555100 -1232621600          1957.0         2021.0   \n",
       "44      123.57  485906030 -1233424020          1975.0         2021.0   \n",
       "...        ...        ...         ...             ...            ...   \n",
       "8735     60.22  552700000  -601300000          1942.0         2021.0   \n",
       "8742     55.85  521810000  -555052000          2013.0         2021.0   \n",
       "8746     61.68  563300000  -614100000          2004.0         2020.0   \n",
       "8760     62.59  582000000  -623508000          1989.0         2021.0   \n",
       "8769     66.86  525522000  -665153000          2014.0         2021.0   \n",
       "\n",
       "                        geometry  \n",
       "12    POINT (123.74000 48.94000)  \n",
       "26    POINT (124.05000 48.83000)  \n",
       "28    POINT (123.23000 48.42000)  \n",
       "39    POINT (123.44000 48.43000)  \n",
       "44    POINT (123.57000 48.99000)  \n",
       "...                          ...  \n",
       "8735   POINT (60.22000 55.45000)  \n",
       "8742   POINT (55.85000 52.30000)  \n",
       "8746   POINT (61.68000 56.55000)  \n",
       "8760   POINT (62.59000 58.33000)  \n",
       "8769   POINT (66.86000 52.92000)  \n",
       "\n",
       "[1193 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>CHEMAINUS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1011500</td>\n      <td>26</td>\n      <td>48.94</td>\n      <td>123.74</td>\n      <td>485606080</td>\n      <td>-1234430000</td>\n      <td>1919.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.74000 48.94000)</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LAKE COWICHAN</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012055</td>\n      <td>40</td>\n      <td>48.83</td>\n      <td>124.05</td>\n      <td>484946000</td>\n      <td>-1240308000</td>\n      <td>1960.0</td>\n      <td>2021.0</td>\n      <td>POINT (124.05000 48.83000)</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DISCOVERY ISLAND</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012475</td>\n      <td>27226</td>\n      <td>48.42</td>\n      <td>123.23</td>\n      <td>482528590</td>\n      <td>-1231332519</td>\n      <td>1997.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.23000 48.42000)</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ESQUIMALT HARBOUR</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012710</td>\n      <td>52</td>\n      <td>48.43</td>\n      <td>123.44</td>\n      <td>482555100</td>\n      <td>-1232621600</td>\n      <td>1957.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.44000 48.43000)</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>GALIANO NORTH</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>10130MN</td>\n      <td>55</td>\n      <td>48.99</td>\n      <td>123.57</td>\n      <td>485906030</td>\n      <td>-1233424020</td>\n      <td>1975.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.57000 48.99000)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8735</th>\n      <td>HOPEDALE (AUT)</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502400</td>\n      <td>6781</td>\n      <td>55.45</td>\n      <td>60.22</td>\n      <td>552700000</td>\n      <td>-601300000</td>\n      <td>1942.0</td>\n      <td>2021.0</td>\n      <td>POINT (60.22000 55.45000)</td>\n    </tr>\n    <tr>\n      <th>8742</th>\n      <td>MARY'S HARBOUR A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502592</td>\n      <td>51918</td>\n      <td>52.30</td>\n      <td>55.85</td>\n      <td>521810000</td>\n      <td>-555052000</td>\n      <td>2013.0</td>\n      <td>2021.0</td>\n      <td>POINT (55.85000 52.30000)</td>\n    </tr>\n    <tr>\n      <th>8746</th>\n      <td>NAIN</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502799</td>\n      <td>10813</td>\n      <td>56.55</td>\n      <td>61.68</td>\n      <td>563300000</td>\n      <td>-614100000</td>\n      <td>2004.0</td>\n      <td>2020.0</td>\n      <td>POINT (61.68000 56.55000)</td>\n    </tr>\n    <tr>\n      <th>8760</th>\n      <td>SAGLEK</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8503249</td>\n      <td>6797</td>\n      <td>58.33</td>\n      <td>62.59</td>\n      <td>582000000</td>\n      <td>-623508000</td>\n      <td>1989.0</td>\n      <td>2021.0</td>\n      <td>POINT (62.59000 58.33000)</td>\n    </tr>\n    <tr>\n      <th>8769</th>\n      <td>WABUSH A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8504177</td>\n      <td>52541</td>\n      <td>52.92</td>\n      <td>66.86</td>\n      <td>525522000</td>\n      <td>-665153000</td>\n      <td>2014.0</td>\n      <td>2021.0</td>\n      <td>POINT (66.86000 52.92000)</td>\n    </tr>\n  </tbody>\n</table>\n<p>1193 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "gdf_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0   latitude   longitude   weekday month day  year   time  \\\n",
       "0           0  59.713938  135.095702  Thursday   May  27  2021  14:00   \n",
       "1           1  51.171303  116.051255  Saturday   May  22  2021  09:00   \n",
       "2           2  50.427560  122.473110    Sunday   May  16  2021  11:00   \n",
       "3           3  51.394930  116.265450  Saturday   May  15  2021  12:00   \n",
       "4           4  51.395059  116.257463    Friday   May  14  2021  12:30   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (135.09570 59.71394)  \n",
       "1  POINT (116.05125 51.17130)  \n",
       "2  POINT (122.47311 50.42756)  \n",
       "3  POINT (116.26545 51.39493)  \n",
       "4  POINT (116.25746 51.39506)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>May</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>POINT (135.09570 59.71394)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>POINT (116.05125 51.17130)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>May</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>POINT (122.47311 50.42756)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>POINT (116.26545 51.39493)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>May</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>POINT (116.25746 51.39506)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "gdf_avalanche.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     Name          Province Climate ID  Station ID  latitude  \\\n",
       "635  PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082         536     50.31   \n",
       "\n",
       "    longitude   Latitude   Longitude  DLY First Year  DLY Last Year  \\\n",
       "635    122.73  501820326 -1224402720          1984.0         2021.0   \n",
       "\n",
       "                       geometry  \n",
       "635  POINT (122.73000 50.31000)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>635</th>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>50.31</td>\n      <td>122.73</td>\n      <td>501820326</td>\n      <td>-1224402720</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>POINT (122.73000 50.31000)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "gdf_station[gdf_station['Station ID'] == 536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0   latitude   longitude   weekday      month day  year   time  \\\n",
       "0              0  59.713938  135.095702  Thursday        May  27  2021  14:00   \n",
       "1              1  51.171303  116.051255  Saturday        May  22  2021  09:00   \n",
       "2              2  50.427560  122.473110    Sunday        May  16  2021  11:00   \n",
       "3              3  51.394930  116.265450  Saturday        May  15  2021  12:00   \n",
       "4              4  51.395059  116.257463    Friday        May  14  2021  12:30   \n",
       "...          ...        ...         ...       ...        ...  ..   ...    ...   \n",
       "2445        2445  51.285000  117.570000  Thursday   November   3  2016  21:06   \n",
       "2446        2446  51.346000  117.532000    Friday    October  28  2016  12:00   \n",
       "2447        2447  50.917750  117.997970  Saturday  September  24  2016  13:32   \n",
       "2448        2448  50.805930  117.922780  Saturday  September  24  2016  11:34   \n",
       "2449        2449  53.500710  119.992500  Thursday      April  28  2016  15:59   \n",
       "\n",
       "                        geometry                     Name          Province  \\\n",
       "0     POINT (135.09570 59.71394)             WHITEHORSE A   YUKON TERRITORY   \n",
       "1     POINT (116.05125 51.17130)                YOHO PARK  BRITISH COLUMBIA   \n",
       "2     POINT (122.47311 50.42756)     PEMBERTON AIRPORT CS  BRITISH COLUMBIA   \n",
       "3     POINT (116.26545 51.39493)                YOHO PARK  BRITISH COLUMBIA   \n",
       "4     POINT (116.25746 51.39506)                YOHO PARK  BRITISH COLUMBIA   \n",
       "...                          ...                      ...               ...   \n",
       "2445  POINT (117.57000 51.28500)                 GOLDEN A  BRITISH COLUMBIA   \n",
       "2446  POINT (117.53200 51.34600)                 GOLDEN A  BRITISH COLUMBIA   \n",
       "2447  POINT (117.99797 50.91775)  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA   \n",
       "2448  POINT (117.92278 50.80593)  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA   \n",
       "2449  POINT (119.99250 53.50071)             BLUE RIVER A  BRITISH COLUMBIA   \n",
       "\n",
       "     Climate ID  Station ID  latitude longitude   Latitude   Longitude  \\\n",
       "0       2101303       50842     60.71    135.07  604234000 -1350402000   \n",
       "1       11790J1        6844     51.44    116.34  512634400 -1162040400   \n",
       "2       1086082         536     50.31    122.73  501820326 -1224402720   \n",
       "3       11790J1        6844     51.44    116.34  512634400 -1162040400   \n",
       "4       11790J1        6844     51.44    116.34  512634400 -1162040400   \n",
       "...         ...         ...       ...       ...        ...         ...   \n",
       "2445    1173210        1364     51.30    116.98  511757000 -1165856000   \n",
       "2446    1173210        1364     51.30    116.98  511757000 -1165856000   \n",
       "2447    1176755       49548     50.96    118.18  505729600 -1181034600   \n",
       "2448    1176755       49548     50.96    118.18  505729600 -1181034600   \n",
       "2449    1160899        1237     52.13    119.29  520744500 -1191722300   \n",
       "\n",
       "      DLY First Year  DLY Last Year      dist  \n",
       "0             2012.0         2021.0  0.996394  \n",
       "1             1992.0         2021.0  0.394426  \n",
       "2             1984.0         2021.0  0.282512  \n",
       "3             1992.0         2021.0  0.087115  \n",
       "4             1992.0         2021.0  0.093979  \n",
       "...              ...            ...       ...  \n",
       "2445          1902.0         2021.0  0.590191  \n",
       "2446          1902.0         2021.0  0.553913  \n",
       "2447          2012.0         2021.0  0.186869  \n",
       "2448          2012.0         2021.0  0.299833  \n",
       "2449          1969.0         2021.0  1.540244  \n",
       "\n",
       "[2450 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>geometry</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>May</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>POINT (135.09570 59.71394)</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>60.71</td>\n      <td>135.07</td>\n      <td>604234000</td>\n      <td>-1350402000</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>POINT (116.05125 51.17130)</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>51.44</td>\n      <td>116.34</td>\n      <td>512634400</td>\n      <td>-1162040400</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>May</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>POINT (122.47311 50.42756)</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>50.31</td>\n      <td>122.73</td>\n      <td>501820326</td>\n      <td>-1224402720</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>POINT (116.26545 51.39493)</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>51.44</td>\n      <td>116.34</td>\n      <td>512634400</td>\n      <td>-1162040400</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>May</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>POINT (116.25746 51.39506)</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>51.44</td>\n      <td>116.34</td>\n      <td>512634400</td>\n      <td>-1162040400</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>2445</td>\n      <td>51.285000</td>\n      <td>117.570000</td>\n      <td>Thursday</td>\n      <td>November</td>\n      <td>3</td>\n      <td>2016</td>\n      <td>21:06</td>\n      <td>POINT (117.57000 51.28500)</td>\n      <td>GOLDEN A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1173210</td>\n      <td>1364</td>\n      <td>51.30</td>\n      <td>116.98</td>\n      <td>511757000</td>\n      <td>-1165856000</td>\n      <td>1902.0</td>\n      <td>2021.0</td>\n      <td>0.590191</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>2446</td>\n      <td>51.346000</td>\n      <td>117.532000</td>\n      <td>Friday</td>\n      <td>October</td>\n      <td>28</td>\n      <td>2016</td>\n      <td>12:00</td>\n      <td>POINT (117.53200 51.34600)</td>\n      <td>GOLDEN A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1173210</td>\n      <td>1364</td>\n      <td>51.30</td>\n      <td>116.98</td>\n      <td>511757000</td>\n      <td>-1165856000</td>\n      <td>1902.0</td>\n      <td>2021.0</td>\n      <td>0.553913</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>2447</td>\n      <td>50.917750</td>\n      <td>117.997970</td>\n      <td>Saturday</td>\n      <td>September</td>\n      <td>24</td>\n      <td>2016</td>\n      <td>13:32</td>\n      <td>POINT (117.99797 50.91775)</td>\n      <td>REVELSTOKE AIRPORT AUTO</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1176755</td>\n      <td>49548</td>\n      <td>50.96</td>\n      <td>118.18</td>\n      <td>505729600</td>\n      <td>-1181034600</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.186869</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>2448</td>\n      <td>50.805930</td>\n      <td>117.922780</td>\n      <td>Saturday</td>\n      <td>September</td>\n      <td>24</td>\n      <td>2016</td>\n      <td>11:34</td>\n      <td>POINT (117.92278 50.80593)</td>\n      <td>REVELSTOKE AIRPORT AUTO</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1176755</td>\n      <td>49548</td>\n      <td>50.96</td>\n      <td>118.18</td>\n      <td>505729600</td>\n      <td>-1181034600</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.299833</td>\n    </tr>\n    <tr>\n      <th>2449</th>\n      <td>2449</td>\n      <td>53.500710</td>\n      <td>119.992500</td>\n      <td>Thursday</td>\n      <td>April</td>\n      <td>28</td>\n      <td>2016</td>\n      <td>15:59</td>\n      <td>POINT (119.99250 53.50071)</td>\n      <td>BLUE RIVER A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1160899</td>\n      <td>1237</td>\n      <td>52.13</td>\n      <td>119.29</td>\n      <td>520744500</td>\n      <td>-1191722300</td>\n      <td>1969.0</td>\n      <td>2021.0</td>\n      <td>1.540244</td>\n    </tr>\n  </tbody>\n</table>\n<p>2450 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def ckdnearest(gdA, gdB):\n",
    "\n",
    "    nA = np.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdB_nearest = gdB.iloc[idx].drop(columns=\"geometry\").reset_index(drop=True)\n",
    "    gdf = pd.concat(\n",
    "        [\n",
    "            gdA.reset_index(drop=True),\n",
    "            gdB_nearest,\n",
    "            pd.Series(dist, name='dist')\n",
    "        ], \n",
    "        axis=1)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "ckdnearest(gdf_avalanche, gdf_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = ckdnearest(gdf_avalanche, gdf_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nRangeIndex: 2450 entries, 0 to 2449\nData columns (total 20 columns):\n #   Column          Non-Null Count  Dtype   \n---  ------          --------------  -----   \n 0   Unnamed: 0      2450 non-null   int64   \n 1   latitude        2450 non-null   object  \n 2   longitude       2450 non-null   object  \n 3   weekday         2450 non-null   object  \n 4   month           2450 non-null   object  \n 5   day             2450 non-null   object  \n 6   year            2450 non-null   object  \n 7   time            2437 non-null   object  \n 8   geometry        2450 non-null   geometry\n 9   Name            2450 non-null   object  \n 10  Province        2450 non-null   object  \n 11  Climate ID      2450 non-null   object  \n 12  Station ID      2450 non-null   int64   \n 13  latitude        2450 non-null   float64 \n 14  longitude       2450 non-null   object  \n 15  Latitude        2450 non-null   int64   \n 16  Longitude       2450 non-null   int64   \n 17  DLY First Year  2450 non-null   float64 \n 18  DLY Last Year   2450 non-null   float64 \n 19  dist            2450 non-null   float64 \ndtypes: float64(4), geometry(1), int64(4), object(11)\nmemory usage: 382.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Name          Province Climate ID  Station ID  latitude  \\\n",
       "12            CHEMAINUS  BRITISH COLUMBIA    1011500          26     48.94   \n",
       "26        LAKE COWICHAN  BRITISH COLUMBIA    1012055          40     48.83   \n",
       "28     DISCOVERY ISLAND  BRITISH COLUMBIA    1012475       27226     48.42   \n",
       "39    ESQUIMALT HARBOUR  BRITISH COLUMBIA    1012710          52     48.43   \n",
       "44        GALIANO NORTH  BRITISH COLUMBIA    10130MN          55     48.99   \n",
       "...                 ...               ...        ...         ...       ...   \n",
       "8735     HOPEDALE (AUT)      NEWFOUNDLAND    8502400        6781     55.45   \n",
       "8742   MARY'S HARBOUR A      NEWFOUNDLAND    8502592       51918     52.30   \n",
       "8746               NAIN      NEWFOUNDLAND    8502799       10813     56.55   \n",
       "8760             SAGLEK      NEWFOUNDLAND    8503249        6797     58.33   \n",
       "8769           WABUSH A      NEWFOUNDLAND    8504177       52541     52.92   \n",
       "\n",
       "     longitude   Latitude   Longitude  DLY First Year  DLY Last Year  \\\n",
       "12      123.74  485606080 -1234430000          1919.0         2021.0   \n",
       "26      124.05  484946000 -1240308000          1960.0         2021.0   \n",
       "28      123.23  482528590 -1231332519          1997.0         2021.0   \n",
       "39      123.44  482555100 -1232621600          1957.0         2021.0   \n",
       "44      123.57  485906030 -1233424020          1975.0         2021.0   \n",
       "...        ...        ...         ...             ...            ...   \n",
       "8735     60.22  552700000  -601300000          1942.0         2021.0   \n",
       "8742     55.85  521810000  -555052000          2013.0         2021.0   \n",
       "8746     61.68  563300000  -614100000          2004.0         2020.0   \n",
       "8760     62.59  582000000  -623508000          1989.0         2021.0   \n",
       "8769     66.86  525522000  -665153000          2014.0         2021.0   \n",
       "\n",
       "                        geometry  \n",
       "12    POINT (123.74000 48.94000)  \n",
       "26    POINT (124.05000 48.83000)  \n",
       "28    POINT (123.23000 48.42000)  \n",
       "39    POINT (123.44000 48.43000)  \n",
       "44    POINT (123.57000 48.99000)  \n",
       "...                          ...  \n",
       "8735   POINT (60.22000 55.45000)  \n",
       "8742   POINT (55.85000 52.30000)  \n",
       "8746   POINT (61.68000 56.55000)  \n",
       "8760   POINT (62.59000 58.33000)  \n",
       "8769   POINT (66.86000 52.92000)  \n",
       "\n",
       "[1193 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>CHEMAINUS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1011500</td>\n      <td>26</td>\n      <td>48.94</td>\n      <td>123.74</td>\n      <td>485606080</td>\n      <td>-1234430000</td>\n      <td>1919.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.74000 48.94000)</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>LAKE COWICHAN</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012055</td>\n      <td>40</td>\n      <td>48.83</td>\n      <td>124.05</td>\n      <td>484946000</td>\n      <td>-1240308000</td>\n      <td>1960.0</td>\n      <td>2021.0</td>\n      <td>POINT (124.05000 48.83000)</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>DISCOVERY ISLAND</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012475</td>\n      <td>27226</td>\n      <td>48.42</td>\n      <td>123.23</td>\n      <td>482528590</td>\n      <td>-1231332519</td>\n      <td>1997.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.23000 48.42000)</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ESQUIMALT HARBOUR</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1012710</td>\n      <td>52</td>\n      <td>48.43</td>\n      <td>123.44</td>\n      <td>482555100</td>\n      <td>-1232621600</td>\n      <td>1957.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.44000 48.43000)</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>GALIANO NORTH</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>10130MN</td>\n      <td>55</td>\n      <td>48.99</td>\n      <td>123.57</td>\n      <td>485906030</td>\n      <td>-1233424020</td>\n      <td>1975.0</td>\n      <td>2021.0</td>\n      <td>POINT (123.57000 48.99000)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8735</th>\n      <td>HOPEDALE (AUT)</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502400</td>\n      <td>6781</td>\n      <td>55.45</td>\n      <td>60.22</td>\n      <td>552700000</td>\n      <td>-601300000</td>\n      <td>1942.0</td>\n      <td>2021.0</td>\n      <td>POINT (60.22000 55.45000)</td>\n    </tr>\n    <tr>\n      <th>8742</th>\n      <td>MARY'S HARBOUR A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502592</td>\n      <td>51918</td>\n      <td>52.30</td>\n      <td>55.85</td>\n      <td>521810000</td>\n      <td>-555052000</td>\n      <td>2013.0</td>\n      <td>2021.0</td>\n      <td>POINT (55.85000 52.30000)</td>\n    </tr>\n    <tr>\n      <th>8746</th>\n      <td>NAIN</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8502799</td>\n      <td>10813</td>\n      <td>56.55</td>\n      <td>61.68</td>\n      <td>563300000</td>\n      <td>-614100000</td>\n      <td>2004.0</td>\n      <td>2020.0</td>\n      <td>POINT (61.68000 56.55000)</td>\n    </tr>\n    <tr>\n      <th>8760</th>\n      <td>SAGLEK</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8503249</td>\n      <td>6797</td>\n      <td>58.33</td>\n      <td>62.59</td>\n      <td>582000000</td>\n      <td>-623508000</td>\n      <td>1989.0</td>\n      <td>2021.0</td>\n      <td>POINT (62.59000 58.33000)</td>\n    </tr>\n    <tr>\n      <th>8769</th>\n      <td>WABUSH A</td>\n      <td>NEWFOUNDLAND</td>\n      <td>8504177</td>\n      <td>52541</td>\n      <td>52.92</td>\n      <td>66.86</td>\n      <td>525522000</td>\n      <td>-665153000</td>\n      <td>2014.0</td>\n      <td>2021.0</td>\n      <td>POINT (66.86000 52.92000)</td>\n    </tr>\n  </tbody>\n</table>\n<p>1193 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "gdf_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Longitude','Latitude','geometry']\n",
    "final_df.drop(cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Point\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "gdf_avalanche.iloc[0:1,:].geometry.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes duplicates from the dataframe\n",
    "ava_df = final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0   latitude   longitude   weekday month day  year   time  \\\n",
       "0           0  59.713938  135.095702  Thursday   May  27  2021  14:00   \n",
       "1           1  51.171303  116.051255  Saturday   May  22  2021  09:00   \n",
       "2           2  50.427560  122.473110    Sunday   May  16  2021  11:00   \n",
       "3           3  51.394930  116.265450  Saturday   May  15  2021  12:00   \n",
       "4           4  51.395059  116.257463    Friday   May  14  2021  12:30   \n",
       "\n",
       "                   Name          Province Climate ID  Station ID  \\\n",
       "0          WHITEHORSE A   YUKON TERRITORY    2101303       50842   \n",
       "1             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "2  PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082         536   \n",
       "3             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "4             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "\n",
       "   DLY First Year  DLY Last Year      dist  \n",
       "0          2012.0         2021.0  0.996394  \n",
       "1          1992.0         2021.0  0.394426  \n",
       "2          1984.0         2021.0  0.282512  \n",
       "3          1992.0         2021.0  0.087115  \n",
       "4          1992.0         2021.0  0.093979  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>May</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>May</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>May</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>May</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "ava_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df['month'] = ava_df['month'].map({'January':1, 'February':2, 'March': 3, 'April':4, 'May': 5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0   latitude   longitude   weekday  month day  year   time  \\\n",
       "0              0  59.713938  135.095702  Thursday      5  27  2021  14:00   \n",
       "1              1  51.171303  116.051255  Saturday      5  22  2021  09:00   \n",
       "2              2  50.427560  122.473110    Sunday      5  16  2021  11:00   \n",
       "3              3  51.394930  116.265450  Saturday      5  15  2021  12:00   \n",
       "4              4  51.395059  116.257463    Friday      5  14  2021  12:30   \n",
       "...          ...        ...         ...       ...    ...  ..   ...    ...   \n",
       "2445        2445  51.285000  117.570000  Thursday     11   3  2016  21:06   \n",
       "2446        2446  51.346000  117.532000    Friday     10  28  2016  12:00   \n",
       "2447        2447  50.917750  117.997970  Saturday      9  24  2016  13:32   \n",
       "2448        2448  50.805930  117.922780  Saturday      9  24  2016  11:34   \n",
       "2449        2449  53.500710  119.992500  Thursday      4  28  2016  15:59   \n",
       "\n",
       "                         Name          Province Climate ID  Station ID  \\\n",
       "0                WHITEHORSE A   YUKON TERRITORY    2101303       50842   \n",
       "1                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "2        PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082         536   \n",
       "3                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "4                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "...                       ...               ...        ...         ...   \n",
       "2445                 GOLDEN A  BRITISH COLUMBIA    1173210        1364   \n",
       "2446                 GOLDEN A  BRITISH COLUMBIA    1173210        1364   \n",
       "2447  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA    1176755       49548   \n",
       "2448  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA    1176755       49548   \n",
       "2449             BLUE RIVER A  BRITISH COLUMBIA    1160899        1237   \n",
       "\n",
       "      DLY First Year  DLY Last Year      dist  \n",
       "0             2012.0         2021.0  0.996394  \n",
       "1             1992.0         2021.0  0.394426  \n",
       "2             1984.0         2021.0  0.282512  \n",
       "3             1992.0         2021.0  0.087115  \n",
       "4             1992.0         2021.0  0.093979  \n",
       "...              ...            ...       ...  \n",
       "2445          1902.0         2021.0  0.590191  \n",
       "2446          1902.0         2021.0  0.553913  \n",
       "2447          2012.0         2021.0  0.186869  \n",
       "2448          2012.0         2021.0  0.299833  \n",
       "2449          1969.0         2021.0  1.540244  \n",
       "\n",
       "[2450 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>5</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>5</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>2445</td>\n      <td>51.285000</td>\n      <td>117.570000</td>\n      <td>Thursday</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2016</td>\n      <td>21:06</td>\n      <td>GOLDEN A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1173210</td>\n      <td>1364</td>\n      <td>1902.0</td>\n      <td>2021.0</td>\n      <td>0.590191</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>2446</td>\n      <td>51.346000</td>\n      <td>117.532000</td>\n      <td>Friday</td>\n      <td>10</td>\n      <td>28</td>\n      <td>2016</td>\n      <td>12:00</td>\n      <td>GOLDEN A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1173210</td>\n      <td>1364</td>\n      <td>1902.0</td>\n      <td>2021.0</td>\n      <td>0.553913</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>2447</td>\n      <td>50.917750</td>\n      <td>117.997970</td>\n      <td>Saturday</td>\n      <td>9</td>\n      <td>24</td>\n      <td>2016</td>\n      <td>13:32</td>\n      <td>REVELSTOKE AIRPORT AUTO</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1176755</td>\n      <td>49548</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.186869</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>2448</td>\n      <td>50.805930</td>\n      <td>117.922780</td>\n      <td>Saturday</td>\n      <td>9</td>\n      <td>24</td>\n      <td>2016</td>\n      <td>11:34</td>\n      <td>REVELSTOKE AIRPORT AUTO</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1176755</td>\n      <td>49548</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.299833</td>\n    </tr>\n    <tr>\n      <th>2449</th>\n      <td>2449</td>\n      <td>53.500710</td>\n      <td>119.992500</td>\n      <td>Thursday</td>\n      <td>4</td>\n      <td>28</td>\n      <td>2016</td>\n      <td>15:59</td>\n      <td>BLUE RIVER A</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1160899</td>\n      <td>1237</td>\n      <td>1969.0</td>\n      <td>2021.0</td>\n      <td>1.540244</td>\n    </tr>\n  </tbody>\n</table>\n<p>2450 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "ava_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0   latitude   longitude   weekday  month day  year   time  \\\n",
       "0           0  59.713938  135.095702  Thursday      5  27  2021  14:00   \n",
       "1           1  51.171303  116.051255  Saturday      5  22  2021  09:00   \n",
       "2           2  50.427560  122.473110    Sunday      5  16  2021  11:00   \n",
       "3           3  51.394930  116.265450  Saturday      5  15  2021  12:00   \n",
       "4           4  51.395059  116.257463    Friday      5  14  2021  12:30   \n",
       "\n",
       "                   Name          Province Climate ID  Station ID  \\\n",
       "0          WHITEHORSE A   YUKON TERRITORY    2101303       50842   \n",
       "1             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "2  PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082         536   \n",
       "3             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "4             YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "\n",
       "   DLY First Year  DLY Last Year      dist  \n",
       "0          2012.0         2021.0  0.996394  \n",
       "1          1992.0         2021.0  0.394426  \n",
       "2          1984.0         2021.0  0.282512  \n",
       "3          1992.0         2021.0  0.087115  \n",
       "4          1992.0         2021.0  0.093979  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>5</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>5</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "ava_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0   latitude   longitude   weekday  month day  year   time  \\\n",
       "0              0  59.713938  135.095702  Thursday      5  27  2021  14:00   \n",
       "1              1  51.171303  116.051255  Saturday      5  22  2021  09:00   \n",
       "2              2  50.427560  122.473110    Sunday      5  16  2021  11:00   \n",
       "3              3  51.394930  116.265450  Saturday      5  15  2021  12:00   \n",
       "4              4  51.395059  116.257463    Friday      5  14  2021  12:30   \n",
       "...          ...        ...         ...       ...    ...  ..   ...    ...   \n",
       "2445        2445  51.285000  117.570000  Thursday     11   3  2016  21:06   \n",
       "2446        2446  51.346000  117.532000    Friday     10  28  2016  12:00   \n",
       "2447        2447  50.917750  117.997970  Saturday      9  24  2016  13:32   \n",
       "2448        2448  50.805930  117.922780  Saturday      9  24  2016  11:34   \n",
       "2449        2449  53.500710  119.992500  Thursday      4  28  2016  15:59   \n",
       "\n",
       "                         Name          Province Climate ID  Station ID  \\\n",
       "0                WHITEHORSE A   YUKON TERRITORY    2101303       50842   \n",
       "1                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "2        PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082         536   \n",
       "3                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "4                   YOHO PARK  BRITISH COLUMBIA    11790J1        6844   \n",
       "...                       ...               ...        ...         ...   \n",
       "2445                 GOLDEN A  BRITISH COLUMBIA    1173210        1364   \n",
       "2446                 GOLDEN A  BRITISH COLUMBIA    1173210        1364   \n",
       "2447  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA    1176755       49548   \n",
       "2448  REVELSTOKE AIRPORT AUTO  BRITISH COLUMBIA    1176755       49548   \n",
       "2449             BLUE RIVER A  BRITISH COLUMBIA    1160899        1237   \n",
       "\n",
       "      DLY First Year  DLY Last Year      dist  \n",
       "0             2012.0         2021.0  0.996394  \n",
       "1             1992.0         2021.0  0.394426  \n",
       "2             1984.0         2021.0  0.282512  \n",
       "3             1992.0         2021.0  0.087115  \n",
       "4             1992.0         2021.0  0.093979  \n",
       "...              ...            ...       ...  \n",
       "2445          1902.0         2021.0  0.590191  \n",
       "2446          1902.0         2021.0  0.553913  \n",
       "2447          2012.0         2021.0  0.186869  \n",
       "2448          2012.0         2021.0  0.299833  \n",
       "2449          1969.0         2021.0  1.540244  \n",
       "\n",
       "[2450 rows x 15 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "ava_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stations = ava_df['Station ID'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stations.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  145,   162,   181,   209,   225,   257,   277,   283,   323,\n",
       "         336,   348,   403,   442,   450,   470,   536,   568,   636,\n",
       "         650,   698,   706,   731,   776,   823,   924,   951,   979,\n",
       "        1041,  1056,  1070,  1095,  1105,  1106,  1115,  1137,  1142,\n",
       "        1180,  1186,  1194,  1199,  1207,  1237,  1309,  1340,  1364,\n",
       "        1367,  1400,  1485,  1504,  2402,  5310,  6610,  6817,  6833,\n",
       "        6838,  6839,  6840,  6843,  6844,  6938,  8935,  8999, 10104,\n",
       "       10222, 10223, 10665, 10761, 10890, 10930, 11005, 26850, 27121,\n",
       "       27195, 27378, 27388, 27533, 29733, 30543, 30669, 31067, 43500,\n",
       "       45267, 46867, 48168, 48208, 48369, 48628, 48688, 48870, 49492,\n",
       "       49548, 49628, 50028, 50089, 50269, 50818, 50842, 51037, 51297,\n",
       "       51517, 51658, 51818, 52398, 52541], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "list_of_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ava_df['Station ID'] = ava_df['Station ID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stations-11-06-21.txt', 'w') as station_data:\n",
    "    station_data.write(str(list_of_stations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "018.csv\n",
      "C:\\cygwin64\\weather_data\\11422019.csv\n",
      "C:\\cygwin64\\weather_data\\11422020.csv\n",
      "C:\\cygwin64\\weather_data\\11422021.csv\n",
      "C:\\cygwin64\\weather_data\\11802016.csv\n",
      "C:\\cygwin64\\weather_data\\11802017.csv\n",
      "C:\\cygwin64\\weather_data\\11802018.csv\n",
      "C:\\cygwin64\\weather_data\\11802019.csv\n",
      "C:\\cygwin64\\weather_data\\11802020.csv\n",
      "C:\\cygwin64\\weather_data\\11802021.csv\n",
      "C:\\cygwin64\\weather_data\\11862016.csv\n",
      "C:\\cygwin64\\weather_data\\11862017.csv\n",
      "C:\\cygwin64\\weather_data\\11862018.csv\n",
      "C:\\cygwin64\\weather_data\\11862019.csv\n",
      "C:\\cygwin64\\weather_data\\11862020.csv\n",
      "C:\\cygwin64\\weather_data\\11862021.csv\n",
      "C:\\cygwin64\\weather_data\\11942016.csv\n",
      "C:\\cygwin64\\weather_data\\11942017.csv\n",
      "C:\\cygwin64\\weather_data\\11942018.csv\n",
      "C:\\cygwin64\\weather_data\\11942019.csv\n",
      "C:\\cygwin64\\weather_data\\11942020.csv\n",
      "C:\\cygwin64\\weather_data\\11942021.csv\n",
      "C:\\cygwin64\\weather_data\\11992016.csv\n",
      "C:\\cygwin64\\weather_data\\11992017.csv\n",
      "C:\\cygwin64\\weather_data\\11992018.csv\n",
      "C:\\cygwin64\\weather_data\\11992019.csv\n",
      "C:\\cygwin64\\weather_data\\11992020.csv\n",
      "C:\\cygwin64\\weather_data\\11992021.csv\n",
      "C:\\cygwin64\\weather_data\\12072016.csv\n",
      "C:\\cygwin64\\weather_data\\12072017.csv\n",
      "C:\\cygwin64\\weather_data\\12072018.csv\n",
      "C:\\cygwin64\\weather_data\\12072019.csv\n",
      "C:\\cygwin64\\weather_data\\12072020.csv\n",
      "C:\\cygwin64\\weather_data\\12072021.csv\n",
      "C:\\cygwin64\\weather_data\\12372016.csv\n",
      "C:\\cygwin64\\weather_data\\12372017.csv\n",
      "C:\\cygwin64\\weather_data\\12372018.csv\n",
      "C:\\cygwin64\\weather_data\\12372019.csv\n",
      "C:\\cygwin64\\weather_data\\12372020.csv\n",
      "C:\\cygwin64\\weather_data\\12372021.csv\n",
      "C:\\cygwin64\\weather_data\\13092016.csv\n",
      "C:\\cygwin64\\weather_data\\13092017.csv\n",
      "C:\\cygwin64\\weather_data\\13092018.csv\n",
      "C:\\cygwin64\\weather_data\\13092019.csv\n",
      "C:\\cygwin64\\weather_data\\13092020.csv\n",
      "C:\\cygwin64\\weather_data\\13092021.csv\n",
      "C:\\cygwin64\\weather_data\\13402016.csv\n",
      "C:\\cygwin64\\weather_data\\13402017.csv\n",
      "C:\\cygwin64\\weather_data\\13402018.csv\n",
      "C:\\cygwin64\\weather_data\\13402019.csv\n",
      "C:\\cygwin64\\weather_data\\13402020.csv\n",
      "C:\\cygwin64\\weather_data\\13402021.csv\n",
      "C:\\cygwin64\\weather_data\\13642016.csv\n",
      "C:\\cygwin64\\weather_data\\13642017.csv\n",
      "C:\\cygwin64\\weather_data\\13642018.csv\n",
      "C:\\cygwin64\\weather_data\\13642019.csv\n",
      "C:\\cygwin64\\weather_data\\13642020.csv\n",
      "C:\\cygwin64\\weather_data\\13642021.csv\n",
      "C:\\cygwin64\\weather_data\\13672016.csv\n",
      "C:\\cygwin64\\weather_data\\13672017.csv\n",
      "C:\\cygwin64\\weather_data\\13672018.csv\n",
      "C:\\cygwin64\\weather_data\\13672019.csv\n",
      "C:\\cygwin64\\weather_data\\13672020.csv\n",
      "C:\\cygwin64\\weather_data\\13672021.csv\n",
      "C:\\cygwin64\\weather_data\\14002016.csv\n",
      "C:\\cygwin64\\weather_data\\14002017.csv\n",
      "C:\\cygwin64\\weather_data\\14002018.csv\n",
      "C:\\cygwin64\\weather_data\\14002019.csv\n",
      "C:\\cygwin64\\weather_data\\14002020.csv\n",
      "C:\\cygwin64\\weather_data\\14002021.csv\n",
      "C:\\cygwin64\\weather_data\\1452016.csv\n",
      "C:\\cygwin64\\weather_data\\1452017.csv\n",
      "C:\\cygwin64\\weather_data\\1452018.csv\n",
      "C:\\cygwin64\\weather_data\\1452019.csv\n",
      "C:\\cygwin64\\weather_data\\1452020.csv\n",
      "C:\\cygwin64\\weather_data\\1452021.csv\n",
      "C:\\cygwin64\\weather_data\\14852016.csv\n",
      "C:\\cygwin64\\weather_data\\14852017.csv\n",
      "C:\\cygwin64\\weather_data\\14852018.csv\n",
      "C:\\cygwin64\\weather_data\\14852019.csv\n",
      "C:\\cygwin64\\weather_data\\14852020.csv\n",
      "C:\\cygwin64\\weather_data\\14852021.csv\n",
      "C:\\cygwin64\\weather_data\\15042016.csv\n",
      "C:\\cygwin64\\weather_data\\15042017.csv\n",
      "C:\\cygwin64\\weather_data\\15042018.csv\n",
      "C:\\cygwin64\\weather_data\\15042019.csv\n",
      "C:\\cygwin64\\weather_data\\15042020.csv\n",
      "C:\\cygwin64\\weather_data\\15042021.csv\n",
      "C:\\cygwin64\\weather_data\\1622016.csv\n",
      "C:\\cygwin64\\weather_data\\1622017.csv\n",
      "C:\\cygwin64\\weather_data\\1622018.csv\n",
      "C:\\cygwin64\\weather_data\\1622019.csv\n",
      "C:\\cygwin64\\weather_data\\1622020.csv\n",
      "C:\\cygwin64\\weather_data\\1622021.csv\n",
      "C:\\cygwin64\\weather_data\\1812016.csv\n",
      "C:\\cygwin64\\weather_data\\1812017.csv\n",
      "C:\\cygwin64\\weather_data\\1812018.csv\n",
      "C:\\cygwin64\\weather_data\\1812019.csv\n",
      "C:\\cygwin64\\weather_data\\1812020.csv\n",
      "C:\\cygwin64\\weather_data\\1812021.csv\n",
      "C:\\cygwin64\\weather_data\\2092016.csv\n",
      "C:\\cygwin64\\weather_data\\2092017.csv\n",
      "C:\\cygwin64\\weather_data\\2092018.csv\n",
      "C:\\cygwin64\\weather_data\\2092019.csv\n",
      "C:\\cygwin64\\weather_data\\2092020.csv\n",
      "C:\\cygwin64\\weather_data\\2092021.csv\n",
      "C:\\cygwin64\\weather_data\\2252016.csv\n",
      "C:\\cygwin64\\weather_data\\2252017.csv\n",
      "C:\\cygwin64\\weather_data\\2252018.csv\n",
      "C:\\cygwin64\\weather_data\\2252019.csv\n",
      "C:\\cygwin64\\weather_data\\2252020.csv\n",
      "C:\\cygwin64\\weather_data\\2252021.csv\n",
      "C:\\cygwin64\\weather_data\\24022016.csv\n",
      "C:\\cygwin64\\weather_data\\24022017.csv\n",
      "C:\\cygwin64\\weather_data\\24022018.csv\n",
      "C:\\cygwin64\\weather_data\\24022019.csv\n",
      "C:\\cygwin64\\weather_data\\24022020.csv\n",
      "C:\\cygwin64\\weather_data\\24022021.csv\n",
      "C:\\cygwin64\\weather_data\\2572016.csv\n",
      "C:\\cygwin64\\weather_data\\2572017.csv\n",
      "C:\\cygwin64\\weather_data\\2572018.csv\n",
      "C:\\cygwin64\\weather_data\\2572019.csv\n",
      "C:\\cygwin64\\weather_data\\2572020.csv\n",
      "C:\\cygwin64\\weather_data\\2572021.csv\n",
      "C:\\cygwin64\\weather_data\\268502016.csv\n",
      "C:\\cygwin64\\weather_data\\268502017.csv\n",
      "C:\\cygwin64\\weather_data\\268502018.csv\n",
      "C:\\cygwin64\\weather_data\\268502019.csv\n",
      "C:\\cygwin64\\weather_data\\268502020.csv\n",
      "C:\\cygwin64\\weather_data\\268502021.csv\n",
      "C:\\cygwin64\\weather_data\\271212016.csv\n",
      "C:\\cygwin64\\weather_data\\271212017.csv\n",
      "C:\\cygwin64\\weather_data\\271212018.csv\n",
      "C:\\cygwin64\\weather_data\\271212019.csv\n",
      "C:\\cygwin64\\weather_data\\271212020.csv\n",
      "C:\\cygwin64\\weather_data\\271212021.csv\n",
      "C:\\cygwin64\\weather_data\\271952016.csv\n",
      "C:\\cygwin64\\weather_data\\271952017.csv\n",
      "C:\\cygwin64\\weather_data\\271952018.csv\n",
      "C:\\cygwin64\\weather_data\\271952019.csv\n",
      "C:\\cygwin64\\weather_data\\271952020.csv\n",
      "C:\\cygwin64\\weather_data\\271952021.csv\n",
      "C:\\cygwin64\\weather_data\\273782016.csv\n",
      "C:\\cygwin64\\weather_data\\273782017.csv\n",
      "C:\\cygwin64\\weather_data\\273782018.csv\n",
      "C:\\cygwin64\\weather_data\\273782019.csv\n",
      "C:\\cygwin64\\weather_data\\273782020.csv\n",
      "C:\\cygwin64\\weather_data\\273782021.csv\n",
      "C:\\cygwin64\\weather_data\\273882016.csv\n",
      "C:\\cygwin64\\weather_data\\273882017.csv\n",
      "C:\\cygwin64\\weather_data\\273882018.csv\n",
      "C:\\cygwin64\\weather_data\\273882019.csv\n",
      "C:\\cygwin64\\weather_data\\273882020.csv\n",
      "C:\\cygwin64\\weather_data\\273882021.csv\n",
      "C:\\cygwin64\\weather_data\\275332016.csv\n",
      "C:\\cygwin64\\weather_data\\275332017.csv\n",
      "C:\\cygwin64\\weather_data\\275332018.csv\n",
      "C:\\cygwin64\\weather_data\\275332019.csv\n",
      "C:\\cygwin64\\weather_data\\275332020.csv\n",
      "C:\\cygwin64\\weather_data\\275332021.csv\n",
      "C:\\cygwin64\\weather_data\\2772016.csv\n",
      "C:\\cygwin64\\weather_data\\2772017.csv\n",
      "C:\\cygwin64\\weather_data\\2772018.csv\n",
      "C:\\cygwin64\\weather_data\\2772019.csv\n",
      "C:\\cygwin64\\weather_data\\2772020.csv\n",
      "C:\\cygwin64\\weather_data\\2772021.csv\n",
      "C:\\cygwin64\\weather_data\\2832016.csv\n",
      "C:\\cygwin64\\weather_data\\2832017.csv\n",
      "C:\\cygwin64\\weather_data\\2832018.csv\n",
      "C:\\cygwin64\\weather_data\\2832019.csv\n",
      "C:\\cygwin64\\weather_data\\2832020.csv\n",
      "C:\\cygwin64\\weather_data\\2832021.csv\n",
      "C:\\cygwin64\\weather_data\\297332016.csv\n",
      "C:\\cygwin64\\weather_data\\297332017.csv\n",
      "C:\\cygwin64\\weather_data\\297332018.csv\n",
      "C:\\cygwin64\\weather_data\\297332019.csv\n",
      "C:\\cygwin64\\weather_data\\297332020.csv\n",
      "C:\\cygwin64\\weather_data\\297332021.csv\n",
      "C:\\cygwin64\\weather_data\\305432016.csv\n",
      "C:\\cygwin64\\weather_data\\305432017.csv\n",
      "C:\\cygwin64\\weather_data\\305432018.csv\n",
      "C:\\cygwin64\\weather_data\\305432019.csv\n",
      "C:\\cygwin64\\weather_data\\305432020.csv\n",
      "C:\\cygwin64\\weather_data\\305432021.csv\n",
      "C:\\cygwin64\\weather_data\\306692016.csv\n",
      "C:\\cygwin64\\weather_data\\306692017.csv\n",
      "C:\\cygwin64\\weather_data\\306692018.csv\n",
      "C:\\cygwin64\\weather_data\\306692019.csv\n",
      "C:\\cygwin64\\weather_data\\306692020.csv\n",
      "C:\\cygwin64\\weather_data\\306692021.csv\n",
      "C:\\cygwin64\\weather_data\\310672016.csv\n",
      "C:\\cygwin64\\weather_data\\310672017.csv\n",
      "C:\\cygwin64\\weather_data\\310672018.csv\n",
      "C:\\cygwin64\\weather_data\\310672019.csv\n",
      "C:\\cygwin64\\weather_data\\310672020.csv\n",
      "C:\\cygwin64\\weather_data\\310672021.csv\n",
      "C:\\cygwin64\\weather_data\\3232016.csv\n",
      "C:\\cygwin64\\weather_data\\3232017.csv\n",
      "C:\\cygwin64\\weather_data\\3232018.csv\n",
      "C:\\cygwin64\\weather_data\\3232019.csv\n",
      "C:\\cygwin64\\weather_data\\3232020.csv\n",
      "C:\\cygwin64\\weather_data\\3232021.csv\n",
      "C:\\cygwin64\\weather_data\\3362016.csv\n",
      "C:\\cygwin64\\weather_data\\3362017.csv\n",
      "C:\\cygwin64\\weather_data\\3362018.csv\n",
      "C:\\cygwin64\\weather_data\\3362019.csv\n",
      "C:\\cygwin64\\weather_data\\3362020.csv\n",
      "C:\\cygwin64\\weather_data\\3362021.csv\n",
      "C:\\cygwin64\\weather_data\\3482016.csv\n",
      "C:\\cygwin64\\weather_data\\3482017.csv\n",
      "C:\\cygwin64\\weather_data\\3482018.csv\n",
      "C:\\cygwin64\\weather_data\\3482019.csv\n",
      "C:\\cygwin64\\weather_data\\3482020.csv\n",
      "C:\\cygwin64\\weather_data\\3482021.csv\n",
      "C:\\cygwin64\\weather_data\\4022016.csv\n",
      "C:\\cygwin64\\weather_data\\4022017.csv\n",
      "C:\\cygwin64\\weather_data\\4022018.csv\n",
      "C:\\cygwin64\\weather_data\\4022019.csv\n",
      "C:\\cygwin64\\weather_data\\4022020.csv\n",
      "C:\\cygwin64\\weather_data\\4022021.csv\n",
      "C:\\cygwin64\\weather_data\\435002016.csv\n",
      "C:\\cygwin64\\weather_data\\435002017.csv\n",
      "C:\\cygwin64\\weather_data\\435002018.csv\n",
      "C:\\cygwin64\\weather_data\\435002019.csv\n",
      "C:\\cygwin64\\weather_data\\435002020.csv\n",
      "C:\\cygwin64\\weather_data\\435002021.csv\n",
      "C:\\cygwin64\\weather_data\\4422016.csv\n",
      "C:\\cygwin64\\weather_data\\4422017.csv\n",
      "C:\\cygwin64\\weather_data\\4422018.csv\n",
      "C:\\cygwin64\\weather_data\\4422019.csv\n",
      "C:\\cygwin64\\weather_data\\4422020.csv\n",
      "C:\\cygwin64\\weather_data\\4422021.csv\n",
      "C:\\cygwin64\\weather_data\\4502016.csv\n",
      "C:\\cygwin64\\weather_data\\4502017.csv\n",
      "C:\\cygwin64\\weather_data\\4502018.csv\n",
      "C:\\cygwin64\\weather_data\\4502019.csv\n",
      "C:\\cygwin64\\weather_data\\4502020.csv\n",
      "C:\\cygwin64\\weather_data\\4502021.csv\n",
      "C:\\cygwin64\\weather_data\\452672016.csv\n",
      "C:\\cygwin64\\weather_data\\452672017.csv\n",
      "C:\\cygwin64\\weather_data\\452672018.csv\n",
      "C:\\cygwin64\\weather_data\\452672019.csv\n",
      "C:\\cygwin64\\weather_data\\452672020.csv\n",
      "C:\\cygwin64\\weather_data\\452672021.csv\n",
      "C:\\cygwin64\\weather_data\\468672016.csv\n",
      "C:\\cygwin64\\weather_data\\468672017.csv\n",
      "C:\\cygwin64\\weather_data\\468672018.csv\n",
      "C:\\cygwin64\\weather_data\\468672019.csv\n",
      "C:\\cygwin64\\weather_data\\468672020.csv\n",
      "C:\\cygwin64\\weather_data\\468672021.csv\n",
      "C:\\cygwin64\\weather_data\\4702016.csv\n",
      "C:\\cygwin64\\weather_data\\4702017.csv\n",
      "C:\\cygwin64\\weather_data\\4702018.csv\n",
      "C:\\cygwin64\\weather_data\\4702019.csv\n",
      "C:\\cygwin64\\weather_data\\4702020.csv\n",
      "C:\\cygwin64\\weather_data\\4702021.csv\n",
      "C:\\cygwin64\\weather_data\\481682016.csv\n",
      "C:\\cygwin64\\weather_data\\481682017.csv\n",
      "C:\\cygwin64\\weather_data\\481682018.csv\n",
      "C:\\cygwin64\\weather_data\\481682019.csv\n",
      "C:\\cygwin64\\weather_data\\481682020.csv\n",
      "C:\\cygwin64\\weather_data\\481682021.csv\n",
      "C:\\cygwin64\\weather_data\\482082016.csv\n",
      "C:\\cygwin64\\weather_data\\482082017.csv\n",
      "C:\\cygwin64\\weather_data\\482082018.csv\n",
      "C:\\cygwin64\\weather_data\\482082019.csv\n",
      "C:\\cygwin64\\weather_data\\482082020.csv\n",
      "C:\\cygwin64\\weather_data\\482082021.csv\n",
      "C:\\cygwin64\\weather_data\\483692016.csv\n",
      "C:\\cygwin64\\weather_data\\483692017.csv\n",
      "C:\\cygwin64\\weather_data\\483692018.csv\n",
      "C:\\cygwin64\\weather_data\\483692019.csv\n",
      "C:\\cygwin64\\weather_data\\483692020.csv\n",
      "C:\\cygwin64\\weather_data\\483692021.csv\n",
      "C:\\cygwin64\\weather_data\\486282016.csv\n",
      "C:\\cygwin64\\weather_data\\486282017.csv\n",
      "C:\\cygwin64\\weather_data\\486282018.csv\n",
      "C:\\cygwin64\\weather_data\\486282019.csv\n",
      "C:\\cygwin64\\weather_data\\486282020.csv\n",
      "C:\\cygwin64\\weather_data\\486282021.csv\n",
      "C:\\cygwin64\\weather_data\\486882016.csv\n",
      "C:\\cygwin64\\weather_data\\486882017.csv\n",
      "C:\\cygwin64\\weather_data\\486882018.csv\n",
      "C:\\cygwin64\\weather_data\\486882019.csv\n",
      "C:\\cygwin64\\weather_data\\486882020.csv\n",
      "C:\\cygwin64\\weather_data\\486882021.csv\n",
      "C:\\cygwin64\\weather_data\\488702016.csv\n",
      "C:\\cygwin64\\weather_data\\488702017.csv\n",
      "C:\\cygwin64\\weather_data\\488702018.csv\n",
      "C:\\cygwin64\\weather_data\\488702019.csv\n",
      "C:\\cygwin64\\weather_data\\488702020.csv\n",
      "C:\\cygwin64\\weather_data\\488702021.csv\n",
      "C:\\cygwin64\\weather_data\\494922016.csv\n",
      "C:\\cygwin64\\weather_data\\494922017.csv\n",
      "C:\\cygwin64\\weather_data\\494922018.csv\n",
      "C:\\cygwin64\\weather_data\\494922019.csv\n",
      "C:\\cygwin64\\weather_data\\494922020.csv\n",
      "C:\\cygwin64\\weather_data\\494922021.csv\n",
      "C:\\cygwin64\\weather_data\\495482016.csv\n",
      "C:\\cygwin64\\weather_data\\495482017.csv\n",
      "C:\\cygwin64\\weather_data\\495482018.csv\n",
      "C:\\cygwin64\\weather_data\\495482019.csv\n",
      "C:\\cygwin64\\weather_data\\495482020.csv\n",
      "C:\\cygwin64\\weather_data\\495482021.csv\n",
      "C:\\cygwin64\\weather_data\\496282016.csv\n",
      "C:\\cygwin64\\weather_data\\496282017.csv\n",
      "C:\\cygwin64\\weather_data\\496282018.csv\n",
      "C:\\cygwin64\\weather_data\\496282019.csv\n",
      "C:\\cygwin64\\weather_data\\496282020.csv\n",
      "C:\\cygwin64\\weather_data\\496282021.csv\n",
      "C:\\cygwin64\\weather_data\\500282016.csv\n",
      "C:\\cygwin64\\weather_data\\500282017.csv\n",
      "C:\\cygwin64\\weather_data\\500282018.csv\n",
      "C:\\cygwin64\\weather_data\\500282019.csv\n",
      "C:\\cygwin64\\weather_data\\500282020.csv\n",
      "C:\\cygwin64\\weather_data\\500282021.csv\n",
      "C:\\cygwin64\\weather_data\\500892016.csv\n",
      "C:\\cygwin64\\weather_data\\500892017.csv\n",
      "C:\\cygwin64\\weather_data\\500892018.csv\n",
      "C:\\cygwin64\\weather_data\\500892019.csv\n",
      "C:\\cygwin64\\weather_data\\500892020.csv\n",
      "C:\\cygwin64\\weather_data\\500892021.csv\n",
      "C:\\cygwin64\\weather_data\\502692016.csv\n",
      "C:\\cygwin64\\weather_data\\502692017.csv\n",
      "C:\\cygwin64\\weather_data\\502692018.csv\n",
      "C:\\cygwin64\\weather_data\\502692019.csv\n",
      "C:\\cygwin64\\weather_data\\502692020.csv\n",
      "C:\\cygwin64\\weather_data\\502692021.csv\n",
      "C:\\cygwin64\\weather_data\\508182016.csv\n",
      "C:\\cygwin64\\weather_data\\508182017.csv\n",
      "C:\\cygwin64\\weather_data\\508182018.csv\n",
      "C:\\cygwin64\\weather_data\\508182019.csv\n",
      "C:\\cygwin64\\weather_data\\508182020.csv\n",
      "C:\\cygwin64\\weather_data\\508182021.csv\n",
      "C:\\cygwin64\\weather_data\\508422016.csv\n",
      "C:\\cygwin64\\weather_data\\508422017.csv\n",
      "C:\\cygwin64\\weather_data\\508422018.csv\n",
      "C:\\cygwin64\\weather_data\\508422019.csv\n",
      "C:\\cygwin64\\weather_data\\508422020.csv\n",
      "C:\\cygwin64\\weather_data\\508422021.csv\n",
      "C:\\cygwin64\\weather_data\\510372016.csv\n",
      "C:\\cygwin64\\weather_data\\510372017.csv\n",
      "C:\\cygwin64\\weather_data\\510372018.csv\n",
      "C:\\cygwin64\\weather_data\\510372019.csv\n",
      "C:\\cygwin64\\weather_data\\510372020.csv\n",
      "C:\\cygwin64\\weather_data\\510372021.csv\n",
      "C:\\cygwin64\\weather_data\\512972016.csv\n",
      "C:\\cygwin64\\weather_data\\512972017.csv\n",
      "C:\\cygwin64\\weather_data\\512972018.csv\n",
      "C:\\cygwin64\\weather_data\\512972019.csv\n",
      "C:\\cygwin64\\weather_data\\512972020.csv\n",
      "C:\\cygwin64\\weather_data\\512972021.csv\n",
      "C:\\cygwin64\\weather_data\\515172016.csv\n",
      "C:\\cygwin64\\weather_data\\515172017.csv\n",
      "C:\\cygwin64\\weather_data\\515172018.csv\n",
      "C:\\cygwin64\\weather_data\\515172019.csv\n",
      "C:\\cygwin64\\weather_data\\515172020.csv\n",
      "C:\\cygwin64\\weather_data\\515172021.csv\n",
      "C:\\cygwin64\\weather_data\\516582016.csv\n",
      "C:\\cygwin64\\weather_data\\516582017.csv\n",
      "C:\\cygwin64\\weather_data\\516582018.csv\n",
      "C:\\cygwin64\\weather_data\\516582019.csv\n",
      "C:\\cygwin64\\weather_data\\516582020.csv\n",
      "C:\\cygwin64\\weather_data\\516582021.csv\n",
      "C:\\cygwin64\\weather_data\\518182016.csv\n",
      "C:\\cygwin64\\weather_data\\518182017.csv\n",
      "C:\\cygwin64\\weather_data\\518182018.csv\n",
      "C:\\cygwin64\\weather_data\\518182019.csv\n",
      "C:\\cygwin64\\weather_data\\518182020.csv\n",
      "C:\\cygwin64\\weather_data\\518182021.csv\n",
      "C:\\cygwin64\\weather_data\\523982016.csv\n",
      "C:\\cygwin64\\weather_data\\523982017.csv\n",
      "C:\\cygwin64\\weather_data\\523982018.csv\n",
      "C:\\cygwin64\\weather_data\\523982019.csv\n",
      "C:\\cygwin64\\weather_data\\523982020.csv\n",
      "C:\\cygwin64\\weather_data\\523982021.csv\n",
      "C:\\cygwin64\\weather_data\\525412016.csv\n",
      "C:\\cygwin64\\weather_data\\525412017.csv\n",
      "C:\\cygwin64\\weather_data\\525412018.csv\n",
      "C:\\cygwin64\\weather_data\\525412019.csv\n",
      "C:\\cygwin64\\weather_data\\525412020.csv\n",
      "C:\\cygwin64\\weather_data\\525412021.csv\n",
      "C:\\cygwin64\\weather_data\\53102016.csv\n",
      "C:\\cygwin64\\weather_data\\53102017.csv\n",
      "C:\\cygwin64\\weather_data\\53102018.csv\n",
      "C:\\cygwin64\\weather_data\\53102019.csv\n",
      "C:\\cygwin64\\weather_data\\53102020.csv\n",
      "C:\\cygwin64\\weather_data\\53102021.csv\n",
      "C:\\cygwin64\\weather_data\\5362016.csv\n",
      "C:\\cygwin64\\weather_data\\5362017.csv\n",
      "C:\\cygwin64\\weather_data\\5362018.csv\n",
      "C:\\cygwin64\\weather_data\\5362019.csv\n",
      "C:\\cygwin64\\weather_data\\5362020.csv\n",
      "C:\\cygwin64\\weather_data\\5362021.csv\n",
      "C:\\cygwin64\\weather_data\\5682016.csv\n",
      "C:\\cygwin64\\weather_data\\5682017.csv\n",
      "C:\\cygwin64\\weather_data\\5682018.csv\n",
      "C:\\cygwin64\\weather_data\\5682019.csv\n",
      "C:\\cygwin64\\weather_data\\5682020.csv\n",
      "C:\\cygwin64\\weather_data\\5682021.csv\n",
      "C:\\cygwin64\\weather_data\\6362016.csv\n",
      "C:\\cygwin64\\weather_data\\6362017.csv\n",
      "C:\\cygwin64\\weather_data\\6362018.csv\n",
      "C:\\cygwin64\\weather_data\\6362019.csv\n",
      "C:\\cygwin64\\weather_data\\6362020.csv\n",
      "C:\\cygwin64\\weather_data\\6362021.csv\n",
      "C:\\cygwin64\\weather_data\\6502016.csv\n",
      "C:\\cygwin64\\weather_data\\6502017.csv\n",
      "C:\\cygwin64\\weather_data\\6502018.csv\n",
      "C:\\cygwin64\\weather_data\\6502019.csv\n",
      "C:\\cygwin64\\weather_data\\6502020.csv\n",
      "C:\\cygwin64\\weather_data\\6502021.csv\n",
      "C:\\cygwin64\\weather_data\\66102016.csv\n",
      "C:\\cygwin64\\weather_data\\66102017.csv\n",
      "C:\\cygwin64\\weather_data\\66102018.csv\n",
      "C:\\cygwin64\\weather_data\\66102019.csv\n",
      "C:\\cygwin64\\weather_data\\66102020.csv\n",
      "C:\\cygwin64\\weather_data\\66102021.csv\n",
      "C:\\cygwin64\\weather_data\\68172016.csv\n",
      "C:\\cygwin64\\weather_data\\68172017.csv\n",
      "C:\\cygwin64\\weather_data\\68172018.csv\n",
      "C:\\cygwin64\\weather_data\\68172019.csv\n",
      "C:\\cygwin64\\weather_data\\68172020.csv\n",
      "C:\\cygwin64\\weather_data\\68172021.csv\n",
      "C:\\cygwin64\\weather_data\\68332016.csv\n",
      "C:\\cygwin64\\weather_data\\68332017.csv\n",
      "C:\\cygwin64\\weather_data\\68332018.csv\n",
      "C:\\cygwin64\\weather_data\\68332019.csv\n",
      "C:\\cygwin64\\weather_data\\68332020.csv\n",
      "C:\\cygwin64\\weather_data\\68332021.csv\n",
      "C:\\cygwin64\\weather_data\\68382016.csv\n",
      "C:\\cygwin64\\weather_data\\68382017.csv\n",
      "C:\\cygwin64\\weather_data\\68382018.csv\n",
      "C:\\cygwin64\\weather_data\\68382019.csv\n",
      "C:\\cygwin64\\weather_data\\68382020.csv\n",
      "C:\\cygwin64\\weather_data\\68382021.csv\n",
      "C:\\cygwin64\\weather_data\\68392016.csv\n",
      "C:\\cygwin64\\weather_data\\68392017.csv\n",
      "C:\\cygwin64\\weather_data\\68392018.csv\n",
      "C:\\cygwin64\\weather_data\\68392019.csv\n",
      "C:\\cygwin64\\weather_data\\68392020.csv\n",
      "C:\\cygwin64\\weather_data\\68392021.csv\n",
      "C:\\cygwin64\\weather_data\\68402016.csv\n",
      "C:\\cygwin64\\weather_data\\68402017.csv\n",
      "C:\\cygwin64\\weather_data\\68402018.csv\n",
      "C:\\cygwin64\\weather_data\\68402019.csv\n",
      "C:\\cygwin64\\weather_data\\68402020.csv\n",
      "C:\\cygwin64\\weather_data\\68402021.csv\n",
      "C:\\cygwin64\\weather_data\\68432016.csv\n",
      "C:\\cygwin64\\weather_data\\68432017.csv\n",
      "C:\\cygwin64\\weather_data\\68432018.csv\n",
      "C:\\cygwin64\\weather_data\\68432019.csv\n",
      "C:\\cygwin64\\weather_data\\68432020.csv\n",
      "C:\\cygwin64\\weather_data\\68432021.csv\n",
      "C:\\cygwin64\\weather_data\\68442016.csv\n",
      "C:\\cygwin64\\weather_data\\68442017.csv\n",
      "C:\\cygwin64\\weather_data\\68442018.csv\n",
      "C:\\cygwin64\\weather_data\\68442019.csv\n",
      "C:\\cygwin64\\weather_data\\68442020.csv\n",
      "C:\\cygwin64\\weather_data\\68442021.csv\n",
      "C:\\cygwin64\\weather_data\\69382016.csv\n",
      "C:\\cygwin64\\weather_data\\69382017.csv\n",
      "C:\\cygwin64\\weather_data\\69382018.csv\n",
      "C:\\cygwin64\\weather_data\\69382019.csv\n",
      "C:\\cygwin64\\weather_data\\69382020.csv\n",
      "C:\\cygwin64\\weather_data\\69382021.csv\n",
      "C:\\cygwin64\\weather_data\\6982016.csv\n",
      "C:\\cygwin64\\weather_data\\6982017.csv\n",
      "C:\\cygwin64\\weather_data\\6982018.csv\n",
      "C:\\cygwin64\\weather_data\\6982019.csv\n",
      "C:\\cygwin64\\weather_data\\6982020.csv\n",
      "C:\\cygwin64\\weather_data\\6982021.csv\n",
      "C:\\cygwin64\\weather_data\\7062016.csv\n",
      "C:\\cygwin64\\weather_data\\7062017.csv\n",
      "C:\\cygwin64\\weather_data\\7062018.csv\n",
      "C:\\cygwin64\\weather_data\\7062019.csv\n",
      "C:\\cygwin64\\weather_data\\7062020.csv\n",
      "C:\\cygwin64\\weather_data\\7062021.csv\n",
      "C:\\cygwin64\\weather_data\\7312016.csv\n",
      "C:\\cygwin64\\weather_data\\7312017.csv\n",
      "C:\\cygwin64\\weather_data\\7312018.csv\n",
      "C:\\cygwin64\\weather_data\\7312019.csv\n",
      "C:\\cygwin64\\weather_data\\7312020.csv\n",
      "C:\\cygwin64\\weather_data\\7312021.csv\n",
      "C:\\cygwin64\\weather_data\\7762016.csv\n",
      "C:\\cygwin64\\weather_data\\7762017.csv\n",
      "C:\\cygwin64\\weather_data\\7762018.csv\n",
      "C:\\cygwin64\\weather_data\\7762019.csv\n",
      "C:\\cygwin64\\weather_data\\7762020.csv\n",
      "C:\\cygwin64\\weather_data\\7762021.csv\n",
      "C:\\cygwin64\\weather_data\\8232016.csv\n",
      "C:\\cygwin64\\weather_data\\8232017.csv\n",
      "C:\\cygwin64\\weather_data\\8232018.csv\n",
      "C:\\cygwin64\\weather_data\\8232019.csv\n",
      "C:\\cygwin64\\weather_data\\8232020.csv\n",
      "C:\\cygwin64\\weather_data\\8232021.csv\n",
      "C:\\cygwin64\\weather_data\\89352016.csv\n",
      "C:\\cygwin64\\weather_data\\89352017.csv\n",
      "C:\\cygwin64\\weather_data\\89352018.csv\n",
      "C:\\cygwin64\\weather_data\\89352019.csv\n",
      "C:\\cygwin64\\weather_data\\89352020.csv\n",
      "C:\\cygwin64\\weather_data\\89352021.csv\n",
      "C:\\cygwin64\\weather_data\\89992016.csv\n",
      "C:\\cygwin64\\weather_data\\89992017.csv\n",
      "C:\\cygwin64\\weather_data\\89992018.csv\n",
      "C:\\cygwin64\\weather_data\\89992019.csv\n",
      "C:\\cygwin64\\weather_data\\89992020.csv\n",
      "C:\\cygwin64\\weather_data\\89992021.csv\n",
      "C:\\cygwin64\\weather_data\\9242016.csv\n",
      "C:\\cygwin64\\weather_data\\9242017.csv\n",
      "C:\\cygwin64\\weather_data\\9242018.csv\n",
      "C:\\cygwin64\\weather_data\\9242019.csv\n",
      "C:\\cygwin64\\weather_data\\9242020.csv\n",
      "C:\\cygwin64\\weather_data\\9242021.csv\n",
      "C:\\cygwin64\\weather_data\\9512016.csv\n",
      "C:\\cygwin64\\weather_data\\9512017.csv\n",
      "C:\\cygwin64\\weather_data\\9512018.csv\n",
      "C:\\cygwin64\\weather_data\\9512019.csv\n",
      "C:\\cygwin64\\weather_data\\9512020.csv\n",
      "C:\\cygwin64\\weather_data\\9512021.csv\n",
      "C:\\cygwin64\\weather_data\\9792016.csv\n",
      "C:\\cygwin64\\weather_data\\9792017.csv\n",
      "C:\\cygwin64\\weather_data\\9792018.csv\n",
      "C:\\cygwin64\\weather_data\\9792019.csv\n",
      "C:\\cygwin64\\weather_data\\9792020.csv\n",
      "C:\\cygwin64\\weather_data\\9792021.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "path = r'C:\\cygwin64\\weather_data' # use your path\n",
    "all_files = glob.glob(path +'\\*.csv')\n",
    "\n",
    "weather_df = pd.DataFrame()\n",
    "for f in all_files:\n",
    "    csv = pd.read_csv(f)\n",
    "    weather_df = weather_df.append(csv)\n",
    "    print(f, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(227968, 31)"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Longitude (x)  Latitude (y)      Station Name Climate ID   Date/Time  \\\n",
       "0         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-01   \n",
       "1         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-02   \n",
       "2         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-03   \n",
       "3         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-04   \n",
       "4         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-05   \n",
       "5         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-06   \n",
       "6         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-07   \n",
       "7         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-08   \n",
       "8         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-09   \n",
       "9         -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-10   \n",
       "10        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-11   \n",
       "11        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-12   \n",
       "12        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-13   \n",
       "13        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-14   \n",
       "14        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-15   \n",
       "15        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-16   \n",
       "16        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-17   \n",
       "17        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-18   \n",
       "18        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-19   \n",
       "19        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-20   \n",
       "20        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-21   \n",
       "21        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-22   \n",
       "22        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-23   \n",
       "23        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-24   \n",
       "24        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-25   \n",
       "25        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-26   \n",
       "26        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-27   \n",
       "27        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-28   \n",
       "28        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-29   \n",
       "29        -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-30   \n",
       "\n",
       "    Year  Month  Day Data Quality  Max Temp (°C)  ... Total Snow (cm)  \\\n",
       "0   2016      1    1          NaN            7.9  ...             NaN   \n",
       "1   2016      1    2          NaN            7.5  ...             NaN   \n",
       "2   2016      1    3          NaN            0.9  ...             NaN   \n",
       "3   2016      1    4          NaN           -3.1  ...             NaN   \n",
       "4   2016      1    5          NaN           -2.8  ...             NaN   \n",
       "5   2016      1    6          NaN           -2.0  ...             NaN   \n",
       "6   2016      1    7          NaN           -7.8  ...             NaN   \n",
       "7   2016      1    8          NaN           -2.8  ...             NaN   \n",
       "8   2016      1    9          NaN           -3.3  ...             NaN   \n",
       "9   2016      1   10          NaN           -2.2  ...             NaN   \n",
       "10  2016      1   11          NaN           -3.9  ...             NaN   \n",
       "11  2016      1   12          NaN           -5.3  ...             NaN   \n",
       "12  2016      1   13          NaN           -3.1  ...             NaN   \n",
       "13  2016      1   14          NaN           -5.7  ...             NaN   \n",
       "14  2016      1   15          NaN           -9.8  ...             NaN   \n",
       "15  2016      1   16          NaN           -8.7  ...             NaN   \n",
       "16  2016      1   17          NaN           -5.3  ...             NaN   \n",
       "17  2016      1   18          NaN           -6.4  ...             NaN   \n",
       "18  2016      1   19          NaN           -5.4  ...             NaN   \n",
       "19  2016      1   20          NaN           -6.3  ...             NaN   \n",
       "20  2016      1   21          NaN           -0.5  ...             NaN   \n",
       "21  2016      1   22          NaN            0.5  ...             NaN   \n",
       "22  2016      1   23          NaN           -2.0  ...             NaN   \n",
       "23  2016      1   24          NaN           -5.3  ...             NaN   \n",
       "24  2016      1   25          NaN           -3.5  ...             NaN   \n",
       "25  2016      1   26          NaN            1.5  ...             NaN   \n",
       "26  2016      1   27          NaN            0.2  ...             NaN   \n",
       "27  2016      1   28          NaN            NaN  ...             NaN   \n",
       "28  2016      1   29          NaN           -6.9  ...             NaN   \n",
       "29  2016      1   30          NaN            NaN  ...             NaN   \n",
       "\n",
       "    Total Snow Flag Total Precip (mm)  Total Precip Flag Snow on Grnd (cm)  \\\n",
       "0                 M               NaN                  M               NaN   \n",
       "1                 M               NaN                  M               NaN   \n",
       "2                 M               NaN                  M               NaN   \n",
       "3                 M               NaN                  M               NaN   \n",
       "4                 M               NaN                  M               NaN   \n",
       "5                 M               NaN                  M               NaN   \n",
       "6                 M               NaN                  M               NaN   \n",
       "7                 M               NaN                  M               NaN   \n",
       "8                 M               NaN                  M               NaN   \n",
       "9                 M               NaN                  M               NaN   \n",
       "10                M               NaN                  M               NaN   \n",
       "11                M               NaN                  M               NaN   \n",
       "12                M               NaN                  M               NaN   \n",
       "13                M               NaN                  M               NaN   \n",
       "14                M               NaN                  M               NaN   \n",
       "15                M               NaN                  M               NaN   \n",
       "16                M               NaN                  M               NaN   \n",
       "17                M               NaN                  M               NaN   \n",
       "18                M               NaN                  M               NaN   \n",
       "19                M               NaN                  M               NaN   \n",
       "20                M               NaN                  M               NaN   \n",
       "21                M               NaN                  M               NaN   \n",
       "22                M               NaN                  M               NaN   \n",
       "23                M               NaN                  M               NaN   \n",
       "24                M               NaN                  M               NaN   \n",
       "25                M               NaN                  M               NaN   \n",
       "26                M               NaN                  M               NaN   \n",
       "27                M               NaN                  M               NaN   \n",
       "28                M               NaN                  M               NaN   \n",
       "29                M               NaN                  M               NaN   \n",
       "\n",
       "    Snow on Grnd Flag Dir of Max Gust (10s deg)  Dir of Max Gust Flag  \\\n",
       "0                 NaN                       NaN                   NaN   \n",
       "1                 NaN                       NaN                   NaN   \n",
       "2                 NaN                       NaN                   NaN   \n",
       "3                 NaN                       NaN                   NaN   \n",
       "4                 NaN                       NaN                   NaN   \n",
       "5                 NaN                       NaN                   NaN   \n",
       "6                 NaN                       NaN                   NaN   \n",
       "7                 NaN                       NaN                   NaN   \n",
       "8                 NaN                       NaN                   NaN   \n",
       "9                 NaN                       NaN                   NaN   \n",
       "10                NaN                       NaN                   NaN   \n",
       "11                NaN                       NaN                   NaN   \n",
       "12                NaN                       NaN                   NaN   \n",
       "13                NaN                       NaN                   NaN   \n",
       "14                NaN                       NaN                   NaN   \n",
       "15                NaN                       NaN                   NaN   \n",
       "16                NaN                       NaN                   NaN   \n",
       "17                NaN                       NaN                   NaN   \n",
       "18                NaN                       NaN                   NaN   \n",
       "19                NaN                       NaN                   NaN   \n",
       "20                NaN                       NaN                   NaN   \n",
       "21                NaN                       NaN                   NaN   \n",
       "22                NaN                       NaN                   NaN   \n",
       "23                NaN                       NaN                   NaN   \n",
       "24                NaN                       NaN                   NaN   \n",
       "25                NaN                       NaN                   NaN   \n",
       "26                NaN                       NaN                   NaN   \n",
       "27                NaN                       NaN                   NaN   \n",
       "28                NaN                       NaN                   NaN   \n",
       "29                NaN                       NaN                   NaN   \n",
       "\n",
       "   Spd of Max Gust (km/h)  Spd of Max Gust Flag  \n",
       "0                     <31                   NaN  \n",
       "1                     <31                   NaN  \n",
       "2                     <31                   NaN  \n",
       "3                     <31                   NaN  \n",
       "4                     <31                   NaN  \n",
       "5                     <31                   NaN  \n",
       "6                     <31                   NaN  \n",
       "7                     <31                   NaN  \n",
       "8                     <31                   NaN  \n",
       "9                     <31                   NaN  \n",
       "10                    <31                   NaN  \n",
       "11                    <31                   NaN  \n",
       "12                    <31                   NaN  \n",
       "13                    <31                   NaN  \n",
       "14                    <31                   NaN  \n",
       "15                    <31                   NaN  \n",
       "16                    <31                   NaN  \n",
       "17                    <31                   NaN  \n",
       "18                    <31                   NaN  \n",
       "19                    <31                   NaN  \n",
       "20                    <31                   NaN  \n",
       "21                    <31                   NaN  \n",
       "22                    <31                   NaN  \n",
       "23                    <31                   NaN  \n",
       "24                    <31                   NaN  \n",
       "25                    <31                   NaN  \n",
       "26                    <31                   NaN  \n",
       "27                    <31                   NaN  \n",
       "28                    <31                   NaN  \n",
       "29                    <31                   NaN  \n",
       "\n",
       "[30 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude (x)</th>\n      <th>Latitude (y)</th>\n      <th>Station Name</th>\n      <th>Climate ID</th>\n      <th>Date/Time</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Data Quality</th>\n      <th>Max Temp (°C)</th>\n      <th>...</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Snow Flag</th>\n      <th>Total Precip (mm)</th>\n      <th>Total Precip Flag</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Snow on Grnd Flag</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Dir of Max Gust Flag</th>\n      <th>Spd of Max Gust (km/h)</th>\n      <th>Spd of Max Gust Flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-01</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>7.9</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-02</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>7.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-03</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.9</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-04</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>-3.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-05</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>-2.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-06</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>-2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-07</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>-7.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-08</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>-2.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-09</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>-3.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-10</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>-2.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-11</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>-3.9</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-12</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>-5.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-13</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>-3.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-14</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>-5.7</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-15</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>-9.8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-16</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>-8.7</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-17</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>-5.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-18</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>-6.4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-19</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>-5.4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-20</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>-6.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-21</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>-0.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-22</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>22</td>\n      <td>NaN</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-23</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>-2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-24</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>-5.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-25</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>-3.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-26</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>1.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-27</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-28</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-29</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>-6.9</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-30</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>30 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "weather_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 227968 entries, 0 to 364\nData columns (total 31 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Longitude (x)              227968 non-null  float64\n 1   Latitude (y)               227968 non-null  float64\n 2   Station Name               227968 non-null  object \n 3   Climate ID                 227968 non-null  object \n 4   Date/Time                  227968 non-null  object \n 5   Year                       227968 non-null  int64  \n 6   Month                      227968 non-null  int64  \n 7   Day                        227968 non-null  int64  \n 8   Data Quality               81586 non-null   object \n 9   Max Temp (°C)              179476 non-null  float64\n 10  Max Temp Flag              5193 non-null    object \n 11  Min Temp (°C)              179845 non-null  float64\n 12  Min Temp Flag              5277 non-null    object \n 13  Mean Temp (°C)             177113 non-null  float64\n 14  Mean Temp Flag             6272 non-null    object \n 15  Heat Deg Days (°C)         177113 non-null  float64\n 16  Heat Deg Days Flag         6272 non-null    object \n 17  Cool Deg Days (°C)         177113 non-null  float64\n 18  Cool Deg Days Flag         6272 non-null    object \n 19  Total Rain (mm)            91284 non-null   float64\n 20  Total Rain Flag            49906 non-null   object \n 21  Total Snow (cm)            91389 non-null   float64\n 22  Total Snow Flag            50477 non-null   object \n 23  Total Precip (mm)          169919 non-null  float64\n 24  Total Precip Flag          22416 non-null   object \n 25  Snow on Grnd (cm)          107682 non-null  float64\n 26  Snow on Grnd Flag          4834 non-null    object \n 27  Dir of Max Gust (10s deg)  44400 non-null   float64\n 28  Dir of Max Gust Flag       14637 non-null   object \n 29  Spd of Max Gust (km/h)     69756 non-null   object \n 30  Spd of Max Gust Flag       14088 non-null   object \ndtypes: float64(12), int64(3), object(16)\nmemory usage: 55.7+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Snow on Grnd Flag','Dir of Max Gust Flag','Snow on Grnd Flag','Heat Deg Days Flag',\n",
    "               'Cool Deg Days Flag','Snow on Grnd Flag','Data Quality','Total Precip Flag','Snow on Grnd Flag','Spd of Max Gust Flag','Dir of Max Gust Flag','Cool Deg Days (°C)','Heat Deg Days (°C)','Heat Deg Days Flag','Cool Deg Days Flag','Max Temp Flag','Total Rain Flag','Min Temp Flag','Mean Temp Flag']\n",
    "\n",
    "weather_df.drop(cols_to_drop, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Longitude (x)  Latitude (y)      Station Name Climate ID   Date/Time  \\\n",
       "0          -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-01   \n",
       "1          -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-02   \n",
       "2          -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-03   \n",
       "3          -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-04   \n",
       "4          -115.19         50.94  NAKISKA RIDGETOP    305MGFF  2016-01-05   \n",
       "..             ...           ...               ...        ...         ...   \n",
       "360        -119.65         49.56     SUMMERLAND CS    112G8L1  2021-12-27   \n",
       "361        -119.65         49.56     SUMMERLAND CS    112G8L1  2021-12-28   \n",
       "362        -119.65         49.56     SUMMERLAND CS    112G8L1  2021-12-29   \n",
       "363        -119.65         49.56     SUMMERLAND CS    112G8L1  2021-12-30   \n",
       "364        -119.65         49.56     SUMMERLAND CS    112G8L1  2021-12-31   \n",
       "\n",
       "     Year  Month  Day  Max Temp (°C)  Min Temp (°C)  Mean Temp (°C)  \\\n",
       "0    2016      1    1            7.9           -0.8             3.6   \n",
       "1    2016      1    2            7.5           -0.2             3.7   \n",
       "2    2016      1    3            0.9           -9.4            -4.3   \n",
       "3    2016      1    4           -3.1           -8.6            -5.9   \n",
       "4    2016      1    5           -2.8           -6.3            -4.6   \n",
       "..    ...    ...  ...            ...            ...             ...   \n",
       "360  2021     12   27            NaN            NaN             NaN   \n",
       "361  2021     12   28            NaN            NaN             NaN   \n",
       "362  2021     12   29            NaN            NaN             NaN   \n",
       "363  2021     12   30            NaN            NaN             NaN   \n",
       "364  2021     12   31            NaN            NaN             NaN   \n",
       "\n",
       "     Total Rain (mm)  Total Snow (cm) Total Snow Flag  Total Precip (mm)  \\\n",
       "0                NaN              NaN               M                NaN   \n",
       "1                NaN              NaN               M                NaN   \n",
       "2                NaN              NaN               M                NaN   \n",
       "3                NaN              NaN               M                NaN   \n",
       "4                NaN              NaN               M                NaN   \n",
       "..               ...              ...             ...                ...   \n",
       "360              NaN              NaN             NaN                NaN   \n",
       "361              NaN              NaN             NaN                NaN   \n",
       "362              NaN              NaN             NaN                NaN   \n",
       "363              NaN              NaN             NaN                NaN   \n",
       "364              NaN              NaN             NaN                NaN   \n",
       "\n",
       "     Snow on Grnd (cm)  Dir of Max Gust (10s deg) Spd of Max Gust (km/h)  \n",
       "0                  NaN                        NaN                    <31  \n",
       "1                  NaN                        NaN                    <31  \n",
       "2                  NaN                        NaN                    <31  \n",
       "3                  NaN                        NaN                    <31  \n",
       "4                  NaN                        NaN                    <31  \n",
       "..                 ...                        ...                    ...  \n",
       "360                NaN                        NaN                    NaN  \n",
       "361                NaN                        NaN                    NaN  \n",
       "362                NaN                        NaN                    NaN  \n",
       "363                NaN                        NaN                    NaN  \n",
       "364                NaN                        NaN                    NaN  \n",
       "\n",
       "[227968 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude (x)</th>\n      <th>Latitude (y)</th>\n      <th>Station Name</th>\n      <th>Climate ID</th>\n      <th>Date/Time</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Rain (mm)</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Snow Flag</th>\n      <th>Total Precip (mm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-01</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7.9</td>\n      <td>-0.8</td>\n      <td>3.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-02</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7.5</td>\n      <td>-0.2</td>\n      <td>3.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-03</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.9</td>\n      <td>-9.4</td>\n      <td>-4.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-04</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-3.1</td>\n      <td>-8.6</td>\n      <td>-5.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-115.19</td>\n      <td>50.94</td>\n      <td>NAKISKA RIDGETOP</td>\n      <td>305MGFF</td>\n      <td>2016-01-05</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-2.8</td>\n      <td>-6.3</td>\n      <td>-4.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>-119.65</td>\n      <td>49.56</td>\n      <td>SUMMERLAND CS</td>\n      <td>112G8L1</td>\n      <td>2021-12-27</td>\n      <td>2021</td>\n      <td>12</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>-119.65</td>\n      <td>49.56</td>\n      <td>SUMMERLAND CS</td>\n      <td>112G8L1</td>\n      <td>2021-12-28</td>\n      <td>2021</td>\n      <td>12</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>-119.65</td>\n      <td>49.56</td>\n      <td>SUMMERLAND CS</td>\n      <td>112G8L1</td>\n      <td>2021-12-29</td>\n      <td>2021</td>\n      <td>12</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>-119.65</td>\n      <td>49.56</td>\n      <td>SUMMERLAND CS</td>\n      <td>112G8L1</td>\n      <td>2021-12-30</td>\n      <td>2021</td>\n      <td>12</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>-119.65</td>\n      <td>49.56</td>\n      <td>SUMMERLAND CS</td>\n      <td>112G8L1</td>\n      <td>2021-12-31</td>\n      <td>2021</td>\n      <td>12</td>\n      <td>31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>227968 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.sort_values(by=['Climate ID','Year','Month','Day'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002079484C4F0>"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "weather_df.groupby('Climate ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df['snow_24_hour'] = weather_df['Total Snow (cm)'].shift(1)\n",
    "# weather_df['snow_48_hour'] = weather_df['Total Snow (cm)'].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Longitude (x)  Latitude (y)      Station Name Climate ID   Date/Time  Year  \\\n",
       "0        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-01  2016   \n",
       "1        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-02  2016   \n",
       "2        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-03  2016   \n",
       "3        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-04  2016   \n",
       "4        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-05  2016   \n",
       "5        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-06  2016   \n",
       "6        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-07  2016   \n",
       "7        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-08  2016   \n",
       "8        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-09  2016   \n",
       "9        -125.27         49.95  CAMPBELL RIVER A    1021261  2016-01-10  2016   \n",
       "\n",
       "   Month  Day  Max Temp (°C)  Min Temp (°C)  Mean Temp (°C)  Total Rain (mm)  \\\n",
       "0      1    1            1.1           -6.0            -2.5              0.0   \n",
       "1      1    2            0.9           -7.5            -3.3              0.0   \n",
       "2      1    3            0.5           -5.2            -2.4              0.0   \n",
       "3      1    4            2.2           -9.4            -3.6              0.0   \n",
       "4      1    5            0.2          -10.1            -5.0              0.6   \n",
       "5      1    6            2.4           -1.5             0.5              1.8   \n",
       "6      1    7            4.0           -6.3            -1.2              0.0   \n",
       "7      1    8            1.1           -3.7            -1.3              0.8   \n",
       "8      1    9            4.6           -2.7             1.0              0.0   \n",
       "9      1   10            3.9           -3.2             0.4              0.0   \n",
       "\n",
       "   Total Snow (cm) Total Snow Flag  Total Precip (mm)  Snow on Grnd (cm)  \\\n",
       "0              0.0             NaN                0.0                0.0   \n",
       "1              0.0             NaN                0.0                0.0   \n",
       "2              0.0             NaN                0.0                0.0   \n",
       "3              0.0             NaN                0.0                0.0   \n",
       "4              3.2             NaN                3.8                0.0   \n",
       "5              0.0             NaN                1.8                3.0   \n",
       "6              0.0             NaN                0.0                2.0   \n",
       "7              0.0             NaN                0.8                0.0   \n",
       "8              0.0             NaN                0.0                0.0   \n",
       "9              0.0             NaN                0.0                0.0   \n",
       "\n",
       "   Dir of Max Gust (10s deg) Spd of Max Gust (km/h)  \n",
       "0                        NaN                    NaN  \n",
       "1                        NaN                    NaN  \n",
       "2                        NaN                    NaN  \n",
       "3                        NaN                    NaN  \n",
       "4                        NaN                    NaN  \n",
       "5                        NaN                    NaN  \n",
       "6                        NaN                    NaN  \n",
       "7                        NaN                    NaN  \n",
       "8                        NaN                    NaN  \n",
       "9                        NaN                    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude (x)</th>\n      <th>Latitude (y)</th>\n      <th>Station Name</th>\n      <th>Climate ID</th>\n      <th>Date/Time</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Rain (mm)</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Snow Flag</th>\n      <th>Total Precip (mm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-01</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.1</td>\n      <td>-6.0</td>\n      <td>-2.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-02</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.9</td>\n      <td>-7.5</td>\n      <td>-3.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-03</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.5</td>\n      <td>-5.2</td>\n      <td>-2.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-04</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2.2</td>\n      <td>-9.4</td>\n      <td>-3.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-05</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.2</td>\n      <td>-10.1</td>\n      <td>-5.0</td>\n      <td>0.6</td>\n      <td>3.2</td>\n      <td>NaN</td>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-06</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2.4</td>\n      <td>-1.5</td>\n      <td>0.5</td>\n      <td>1.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.8</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-07</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>7</td>\n      <td>4.0</td>\n      <td>-6.3</td>\n      <td>-1.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-08</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1.1</td>\n      <td>-3.7</td>\n      <td>-1.3</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-09</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>9</td>\n      <td>4.6</td>\n      <td>-2.7</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-125.27</td>\n      <td>49.95</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2016-01-10</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3.9</td>\n      <td>-3.2</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "weather_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nRangeIndex: 2450 entries, 0 to 2449\nData columns (total 15 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Unnamed: 0      2450 non-null   int64  \n 1   latitude        2450 non-null   object \n 2   longitude       2450 non-null   object \n 3   weekday         2450 non-null   object \n 4   month           2450 non-null   int64  \n 5   day             2450 non-null   object \n 6   year            2450 non-null   object \n 7   time            2437 non-null   object \n 8   Name            2450 non-null   object \n 9   Province        2450 non-null   object \n 10  Climate ID      2450 non-null   object \n 11  Station ID      2450 non-null   object \n 12  DLY First Year  2450 non-null   float64\n 13  DLY Last Year   2450 non-null   float64\n 14  dist            2450 non-null   float64\ndtypes: float64(3), int64(2), object(10)\nmemory usage: 287.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ava_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df['year'] = ava_df['year'].astype('int')\n",
    "\n",
    "ava_df['month'] = ava_df['month'].astype('int')\n",
    "ava_df['day'] = ava_df['day'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_df['avalanche_occured'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0   latitude   longitude   weekday  month  day  year   time  \\\n",
       "0           0  59.713938  135.095702  Thursday      5   27  2021  14:00   \n",
       "1           1  51.171303  116.051255  Saturday      5   22  2021  09:00   \n",
       "2           2  50.427560  122.473110    Sunday      5   16  2021  11:00   \n",
       "3           3  51.394930  116.265450  Saturday      5   15  2021  12:00   \n",
       "4           4  51.395059  116.257463    Friday      5   14  2021  12:30   \n",
       "\n",
       "                   Name          Province Climate ID Station ID  \\\n",
       "0          WHITEHORSE A   YUKON TERRITORY    2101303      50842   \n",
       "1             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "2  PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082        536   \n",
       "3             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "4             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "\n",
       "   DLY First Year  DLY Last Year      dist  avalanche_occured  \n",
       "0          2012.0         2021.0  0.996394                  1  \n",
       "1          1992.0         2021.0  0.394426                  1  \n",
       "2          1984.0         2021.0  0.282512                  1  \n",
       "3          1992.0         2021.0  0.087115                  1  \n",
       "4          1992.0         2021.0  0.093979                  1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n      <th>avalanche_occured</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>5</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>5</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "ava_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.merge(ava_df, weather_df,  how='right', left_on=['Name', 'year', 'month', 'day'], right_on = ['Station Name', 'Year', 'Month', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 228422 entries, 0 to 228421\nData columns (total 34 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Unnamed: 0                 2435 non-null    float64\n 1   latitude                   2435 non-null    object \n 2   longitude                  2435 non-null    object \n 3   weekday                    2435 non-null    object \n 4   month                      2435 non-null    float64\n 5   day                        2435 non-null    float64\n 6   year                       2435 non-null    float64\n 7   time                       2435 non-null    object \n 8   Name                       2435 non-null    object \n 9   Province                   2435 non-null    object \n 10  Climate ID_x               2435 non-null    object \n 11  Station ID                 2435 non-null    object \n 12  DLY First Year             2435 non-null    float64\n 13  DLY Last Year              2435 non-null    float64\n 14  dist                       2435 non-null    float64\n 15  avalanche_occured          2435 non-null    float64\n 16  Longitude (x)              228422 non-null  float64\n 17  Latitude (y)               228422 non-null  float64\n 18  Station Name               228422 non-null  object \n 19  Climate ID_y               228422 non-null  object \n 20  Date/Time                  228422 non-null  object \n 21  Year                       228422 non-null  int64  \n 22  Month                      228422 non-null  int64  \n 23  Day                        228422 non-null  int64  \n 24  Max Temp (°C)              179892 non-null  float64\n 25  Min Temp (°C)              180263 non-null  float64\n 26  Mean Temp (°C)             177529 non-null  float64\n 27  Total Rain (mm)            91473 non-null   float64\n 28  Total Snow (cm)            91578 non-null   float64\n 29  Total Snow Flag            50530 non-null   object \n 30  Total Precip (mm)          170272 non-null  float64\n 31  Snow on Grnd (cm)          108046 non-null  float64\n 32  Dir of Max Gust (10s deg)  44520 non-null   float64\n 33  Spd of Max Gust (km/h)     69890 non-null   object \ndtypes: float64(18), int64(3), object(13)\nmemory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['avalanche_occured'].fillna(value= 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "228417    0.0\n",
       "228418    0.0\n",
       "228419    0.0\n",
       "228420    0.0\n",
       "228421    0.0\n",
       "Name: avalanche_occured, Length: 228422, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "new_df['avalanche_occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Unnamed: 0   latitude   longitude   weekday  month   day    year  \\\n",
       "9311           NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "79995          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "28615          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "361            NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "154193         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "156264         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "64155          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "72419          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "56640          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "161974         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "8374           NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "192364         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "215912      2129.0  51.160460  116.101150  Saturday    1.0  27.0  2018.0   \n",
       "122201         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "190661         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "46714          NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "153781         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "204866         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "188425         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "179474         NaN        NaN         NaN       NaN    NaN   NaN     NaN   \n",
       "\n",
       "         time       Name          Province  ... Max Temp (°C) Min Temp (°C)  \\\n",
       "9311      NaN        NaN               NaN  ...          30.0           9.5   \n",
       "79995     NaN        NaN               NaN  ...          23.0          12.5   \n",
       "28615     NaN        NaN               NaN  ...          18.0          10.0   \n",
       "361       NaN        NaN               NaN  ...           4.0          -2.5   \n",
       "154193    NaN        NaN               NaN  ...           6.6          -7.2   \n",
       "156264    NaN        NaN               NaN  ...           6.1          -8.2   \n",
       "64155     NaN        NaN               NaN  ...           NaN           NaN   \n",
       "72419     NaN        NaN               NaN  ...           NaN           NaN   \n",
       "56640     NaN        NaN               NaN  ...           1.0          -1.7   \n",
       "161974    NaN        NaN               NaN  ...          22.7           8.0   \n",
       "8374      NaN        NaN               NaN  ...           4.0          -2.5   \n",
       "192364    NaN        NaN               NaN  ...          17.4          13.7   \n",
       "215912  11:05  YOHO PARK  BRITISH COLUMBIA  ...          -7.1         -13.1   \n",
       "122201    NaN        NaN               NaN  ...           1.0          -1.5   \n",
       "190661    NaN        NaN               NaN  ...          -5.7          -8.2   \n",
       "46714     NaN        NaN               NaN  ...          17.8          -1.1   \n",
       "153781    NaN        NaN               NaN  ...           4.7          -5.4   \n",
       "204866    NaN        NaN               NaN  ...           5.3           1.5   \n",
       "188425    NaN        NaN               NaN  ...          14.5           8.9   \n",
       "179474    NaN        NaN               NaN  ...          14.7           5.7   \n",
       "\n",
       "        Mean Temp (°C)  Total Rain (mm)  Total Snow (cm)  Total Snow Flag  \\\n",
       "9311              19.8              0.0              0.0              NaN   \n",
       "79995             17.8              0.0              0.0              NaN   \n",
       "28615             14.0              4.8              0.0              NaN   \n",
       "361                0.8              2.4              0.0              NaN   \n",
       "154193            -0.3              NaN              NaN                M   \n",
       "156264            -1.1              NaN              NaN                M   \n",
       "64155              NaN              NaN              NaN              NaN   \n",
       "72419              NaN              NaN              NaN              NaN   \n",
       "56640             -0.3              NaN              NaN              NaN   \n",
       "161974            15.3              NaN              NaN              NaN   \n",
       "8374               0.8              0.6              0.0              NaN   \n",
       "192364            15.5              NaN              NaN              NaN   \n",
       "215912           -10.1              NaN              NaN                M   \n",
       "122201            -0.3              0.0              6.0              NaN   \n",
       "190661            -7.0              NaN              NaN              NaN   \n",
       "46714              8.4              NaN              NaN                M   \n",
       "153781            -0.4              NaN              NaN                M   \n",
       "204866             3.4              NaN              NaN                M   \n",
       "188425            11.7              NaN              NaN                M   \n",
       "179474            10.2              NaN              NaN              NaN   \n",
       "\n",
       "        Total Precip (mm)  Snow on Grnd (cm) Dir of Max Gust (10s deg)  \\\n",
       "9311                  0.0                0.0                       NaN   \n",
       "79995                 0.0                0.0                       NaN   \n",
       "28615                 4.8                0.0                       NaN   \n",
       "361                   2.4                2.0                       NaN   \n",
       "154193                0.0                3.0                      21.0   \n",
       "156264                0.0                0.0                      24.0   \n",
       "64155                 NaN                NaN                       NaN   \n",
       "72419                 NaN                NaN                       NaN   \n",
       "56640                37.6               37.0                       NaN   \n",
       "161974                0.0                NaN                      32.0   \n",
       "8374                  0.6                0.0                       NaN   \n",
       "192364                2.0                NaN                      17.0   \n",
       "215912                0.0              104.0                       NaN   \n",
       "122201                9.4               40.0                       NaN   \n",
       "190661                0.0                NaN                      22.0   \n",
       "46714                 0.0                NaN                      34.0   \n",
       "153781                0.0               23.0                       NaN   \n",
       "204866                1.0                0.0                       NaN   \n",
       "188425               17.8                NaN                      20.0   \n",
       "179474                0.0                NaN                       NaN   \n",
       "\n",
       "       Spd of Max Gust (km/h)  \n",
       "9311                      NaN  \n",
       "79995                     NaN  \n",
       "28615                     NaN  \n",
       "361                       NaN  \n",
       "154193                     37  \n",
       "156264                     54  \n",
       "64155                     NaN  \n",
       "72419                     NaN  \n",
       "56640                     NaN  \n",
       "161974                   36.0  \n",
       "8374                      NaN  \n",
       "192364                   48.0  \n",
       "215912                    <31  \n",
       "122201                    NaN  \n",
       "190661                   42.0  \n",
       "46714                      39  \n",
       "153781                    <31  \n",
       "204866                    <31  \n",
       "188425                   74.0  \n",
       "179474                    NaN  \n",
       "\n",
       "[20 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>...</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Rain (mm)</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Snow Flag</th>\n      <th>Total Precip (mm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9311</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>9.5</td>\n      <td>19.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>23.0</td>\n      <td>12.5</td>\n      <td>17.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28615</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>18.0</td>\n      <td>10.0</td>\n      <td>14.0</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>-2.5</td>\n      <td>0.8</td>\n      <td>2.4</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.4</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>154193</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.6</td>\n      <td>-7.2</td>\n      <td>-0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>156264</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6.1</td>\n      <td>-8.2</td>\n      <td>-1.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>64155</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>72419</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>56640</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-1.7</td>\n      <td>-0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37.6</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>161974</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>22.7</td>\n      <td>8.0</td>\n      <td>15.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>8374</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>-2.5</td>\n      <td>0.8</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>192364</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>17.4</td>\n      <td>13.7</td>\n      <td>15.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>215912</th>\n      <td>2129.0</td>\n      <td>51.160460</td>\n      <td>116.101150</td>\n      <td>Saturday</td>\n      <td>1.0</td>\n      <td>27.0</td>\n      <td>2018.0</td>\n      <td>11:05</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>...</td>\n      <td>-7.1</td>\n      <td>-13.1</td>\n      <td>-10.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>0.0</td>\n      <td>104.0</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>122201</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-1.5</td>\n      <td>-0.3</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>9.4</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>190661</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>-5.7</td>\n      <td>-8.2</td>\n      <td>-7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>46714</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>17.8</td>\n      <td>-1.1</td>\n      <td>8.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>34.0</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>153781</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.7</td>\n      <td>-5.4</td>\n      <td>-0.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>204866</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>5.3</td>\n      <td>1.5</td>\n      <td>3.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>188425</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>14.5</td>\n      <td>8.9</td>\n      <td>11.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>17.8</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>179474</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>14.7</td>\n      <td>5.7</td>\n      <td>10.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "new_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0   latitude   longitude   weekday  month  day  year   time  \\\n",
       "0           0  59.713938  135.095702  Thursday      5   27  2021  14:00   \n",
       "1           1  51.171303  116.051255  Saturday      5   22  2021  09:00   \n",
       "2           2  50.427560  122.473110    Sunday      5   16  2021  11:00   \n",
       "3           3  51.394930  116.265450  Saturday      5   15  2021  12:00   \n",
       "4           4  51.395059  116.257463    Friday      5   14  2021  12:30   \n",
       "\n",
       "                   Name          Province Climate ID Station ID  \\\n",
       "0          WHITEHORSE A   YUKON TERRITORY    2101303      50842   \n",
       "1             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "2  PEMBERTON AIRPORT CS  BRITISH COLUMBIA    1086082        536   \n",
       "3             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "4             YOHO PARK  BRITISH COLUMBIA    11790J1       6844   \n",
       "\n",
       "   DLY First Year  DLY Last Year      dist  avalanche_occured  \n",
       "0          2012.0         2021.0  0.996394                  1  \n",
       "1          1992.0         2021.0  0.394426                  1  \n",
       "2          1984.0         2021.0  0.282512                  1  \n",
       "3          1992.0         2021.0  0.087115                  1  \n",
       "4          1992.0         2021.0  0.093979                  1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>month</th>\n      <th>day</th>\n      <th>year</th>\n      <th>time</th>\n      <th>Name</th>\n      <th>Province</th>\n      <th>Climate ID</th>\n      <th>Station ID</th>\n      <th>DLY First Year</th>\n      <th>DLY Last Year</th>\n      <th>dist</th>\n      <th>avalanche_occured</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.713938</td>\n      <td>135.095702</td>\n      <td>Thursday</td>\n      <td>5</td>\n      <td>27</td>\n      <td>2021</td>\n      <td>14:00</td>\n      <td>WHITEHORSE A</td>\n      <td>YUKON TERRITORY</td>\n      <td>2101303</td>\n      <td>50842</td>\n      <td>2012.0</td>\n      <td>2021.0</td>\n      <td>0.996394</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>51.171303</td>\n      <td>116.051255</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>22</td>\n      <td>2021</td>\n      <td>09:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.394426</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>50.427560</td>\n      <td>122.473110</td>\n      <td>Sunday</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2021</td>\n      <td>11:00</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>1086082</td>\n      <td>536</td>\n      <td>1984.0</td>\n      <td>2021.0</td>\n      <td>0.282512</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>51.394930</td>\n      <td>116.265450</td>\n      <td>Saturday</td>\n      <td>5</td>\n      <td>15</td>\n      <td>2021</td>\n      <td>12:00</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.087115</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>51.395059</td>\n      <td>116.257463</td>\n      <td>Friday</td>\n      <td>5</td>\n      <td>14</td>\n      <td>2021</td>\n      <td>12:30</td>\n      <td>YOHO PARK</td>\n      <td>BRITISH COLUMBIA</td>\n      <td>11790J1</td>\n      <td>6844</td>\n      <td>1992.0</td>\n      <td>2021.0</td>\n      <td>0.093979</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "ava_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 228422 entries, 0 to 228421\nData columns (total 34 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Unnamed: 0                 2435 non-null    float64\n 1   latitude                   2435 non-null    object \n 2   longitude                  2435 non-null    object \n 3   weekday                    2435 non-null    object \n 4   month                      2435 non-null    float64\n 5   day                        2435 non-null    float64\n 6   year                       2435 non-null    float64\n 7   time                       2435 non-null    object \n 8   Name                       2435 non-null    object \n 9   Province                   2435 non-null    object \n 10  Climate ID_x               2435 non-null    object \n 11  Station ID                 2435 non-null    object \n 12  DLY First Year             2435 non-null    float64\n 13  DLY Last Year              2435 non-null    float64\n 14  dist                       2435 non-null    float64\n 15  avalanche_occured          228422 non-null  float64\n 16  Longitude (x)              228422 non-null  float64\n 17  Latitude (y)               228422 non-null  float64\n 18  Station Name               228422 non-null  object \n 19  Climate ID_y               228422 non-null  object \n 20  Date/Time                  228422 non-null  object \n 21  Year                       228422 non-null  int64  \n 22  Month                      228422 non-null  int64  \n 23  Day                        228422 non-null  int64  \n 24  Max Temp (°C)              179892 non-null  float64\n 25  Min Temp (°C)              180263 non-null  float64\n 26  Mean Temp (°C)             177529 non-null  float64\n 27  Total Rain (mm)            91473 non-null   float64\n 28  Total Snow (cm)            91578 non-null   float64\n 29  Total Snow Flag            50530 non-null   object \n 30  Total Precip (mm)          170272 non-null  float64\n 31  Snow on Grnd (cm)          108046 non-null  float64\n 32  Dir of Max Gust (10s deg)  44520 non-null   float64\n 33  Spd of Max Gust (km/h)     69890 non-null   object \ndtypes: float64(18), int64(3), object(13)\nmemory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "new_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 228422 entries, 0 to 228421\nData columns (total 34 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Unnamed: 0                 2435 non-null    float64\n 1   latitude                   2435 non-null    object \n 2   longitude                  2435 non-null    object \n 3   weekday                    2435 non-null    object \n 4   month                      2435 non-null    float64\n 5   day                        2435 non-null    float64\n 6   year                       2435 non-null    float64\n 7   time                       2435 non-null    object \n 8   Name                       2435 non-null    object \n 9   Province                   2435 non-null    object \n 10  Climate ID_x               2435 non-null    object \n 11  Station ID                 2435 non-null    object \n 12  DLY First Year             2435 non-null    float64\n 13  DLY Last Year              2435 non-null    float64\n 14  dist                       2435 non-null    float64\n 15  avalanche_occured          228422 non-null  float64\n 16  Longitude (x)              228422 non-null  float64\n 17  Latitude (y)               228422 non-null  float64\n 18  Station Name               228422 non-null  object \n 19  Climate ID_y               228422 non-null  object \n 20  Date/Time                  228422 non-null  object \n 21  Year                       228422 non-null  int64  \n 22  Month                      228422 non-null  int64  \n 23  Day                        228422 non-null  int64  \n 24  Max Temp (°C)              179892 non-null  float64\n 25  Min Temp (°C)              180263 non-null  float64\n 26  Mean Temp (°C)             177529 non-null  float64\n 27  Total Rain (mm)            91473 non-null   float64\n 28  Total Snow (cm)            91578 non-null   float64\n 29  Total Snow Flag            50530 non-null   object \n 30  Total Precip (mm)          170272 non-null  float64\n 31  Snow on Grnd (cm)          108046 non-null  float64\n 32  Dir of Max Gust (10s deg)  44520 non-null   float64\n 33  Spd of Max Gust (km/h)     69890 non-null   object \ndtypes: float64(18), int64(3), object(13)\nmemory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (new_df['Total Snow Flag'] == 'M')\n",
    "new_df['Total Snow (cm)'][mask] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 228422 entries, 0 to 228421\nData columns (total 34 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   Unnamed: 0                 2435 non-null    float64\n 1   latitude                   2435 non-null    object \n 2   longitude                  2435 non-null    object \n 3   weekday                    2435 non-null    object \n 4   month                      2435 non-null    float64\n 5   day                        2435 non-null    float64\n 6   year                       2435 non-null    float64\n 7   time                       2435 non-null    object \n 8   Name                       2435 non-null    object \n 9   Province                   2435 non-null    object \n 10  Climate ID_x               2435 non-null    object \n 11  Station ID                 2435 non-null    object \n 12  DLY First Year             2435 non-null    float64\n 13  DLY Last Year              2435 non-null    float64\n 14  dist                       2435 non-null    float64\n 15  avalanche_occured          228422 non-null  float64\n 16  Longitude (x)              228422 non-null  float64\n 17  Latitude (y)               228422 non-null  float64\n 18  Station Name               228422 non-null  object \n 19  Climate ID_y               228422 non-null  object \n 20  Date/Time                  228422 non-null  object \n 21  Year                       228422 non-null  int64  \n 22  Month                      228422 non-null  int64  \n 23  Day                        228422 non-null  int64  \n 24  Max Temp (°C)              179892 non-null  float64\n 25  Min Temp (°C)              180263 non-null  float64\n 26  Mean Temp (°C)             177529 non-null  float64\n 27  Total Rain (mm)            91473 non-null   float64\n 28  Total Snow (cm)            137708 non-null  float64\n 29  Total Snow Flag            50530 non-null   object \n 30  Total Precip (mm)          170272 non-null  float64\n 31  Snow on Grnd (cm)          108046 non-null  float64\n 32  Dir of Max Gust (10s deg)  44520 non-null   float64\n 33  Spd of Max Gust (km/h)     69890 non-null   object \ndtypes: float64(18), int64(3), object(13)\nmemory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = ['Unnamed: 0','Climate ID_x','Date/Time','Total Snow Flag','Longitude (x)','Latitude (y)','DLY First Year','DLY Last Year','dist','year','month','day','Name','Province']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(cols_to_remove,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 228422 entries, 0 to 228421\nData columns (total 20 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   latitude                   2435 non-null    object \n 1   longitude                  2435 non-null    object \n 2   weekday                    2435 non-null    object \n 3   time                       2435 non-null    object \n 4   Station ID                 2435 non-null    object \n 5   avalanche_occured          228422 non-null  float64\n 6   Station Name               228422 non-null  object \n 7   Climate ID_y               228422 non-null  object \n 8   Year                       228422 non-null  int64  \n 9   Month                      228422 non-null  int64  \n 10  Day                        228422 non-null  int64  \n 11  Max Temp (°C)              179892 non-null  float64\n 12  Min Temp (°C)              180263 non-null  float64\n 13  Mean Temp (°C)             177529 non-null  float64\n 14  Total Rain (mm)            91473 non-null   float64\n 15  Total Snow (cm)            137708 non-null  float64\n 16  Total Precip (mm)          170272 non-null  float64\n 17  Snow on Grnd (cm)          108046 non-null  float64\n 18  Dir of Max Gust (10s deg)  44520 non-null   float64\n 19  Spd of Max Gust (km/h)     69890 non-null   object \ndtypes: float64(9), int64(3), object(8)\nmemory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       latitude longitude weekday time Station ID  avalanche_occured  \\\n",
       "225431      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "177962      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "116320      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "126053      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "106054      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "1644        NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "5000        NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "143003      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "139986      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "223699      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "161862      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "2454        NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "9207        NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "142024      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "11114       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "204931      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "191677      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "33696       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "130519      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "180235      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "\n",
       "                   Station Name Climate ID_y  Year  Month  Day  Max Temp (°C)  \\\n",
       "225431           POINT PELEE CS      613P001  2019     10   27           15.3   \n",
       "177962            CAP-MADELEINE      7051163  2016      4   17           11.1   \n",
       "116320          CLEARWATER AUTO      1161650  2021     11   24            NaN   \n",
       "126053             REVELSTOKE A      1176745  2018      4   29           12.7   \n",
       "106054            KIMBERLEY PCC      1154203  2017     10   30            6.5   \n",
       "1644           CAMPBELL RIVER A      1021261  2020      7    2           18.5   \n",
       "5000               FANNY ISLAND      1022795  2017      9    8           14.8   \n",
       "143003            PLEASANT CAMP      1206197  2016      8   27           24.0   \n",
       "139986             DEASE LAKE A      1192341  2020      5   25           12.4   \n",
       "223699           WILLOW CREEK 1      306GE70  2021      1   29           -2.7   \n",
       "161862            JASPER WARDEN      3053536  2020      3   24           -3.2   \n",
       "2454        COURTENAY PUNTLEDGE      1021989  2016      9   19           16.5   \n",
       "9207     QUINSAM RIVER HATCHERY      1026639  2017      3   12            8.5   \n",
       "142024                    ATLIN      1200560  2019     12   23           -0.5   \n",
       "11114   ALBERNI ROBERTSON CREEK      1030230  2016      5   31           25.5   \n",
       "204931                NELSON CS      1145M29  2018      1   23            1.7   \n",
       "191677   HOWE SOUND - PAM ROCKS      10459NN  2017     10   28           15.4   \n",
       "33696                   HOUSTON      1073615  2018      3   11            NaN   \n",
       "130519               CHETWYND A      1181508  2018      6   28           21.0   \n",
       "180235                  GASPE A      7052601  2016      7    7           14.3   \n",
       "\n",
       "        Min Temp (°C)  Mean Temp (°C)  Total Rain (mm)  Total Snow (cm)  \\\n",
       "225431            9.4            12.4              NaN              NaN   \n",
       "177962            1.6             6.4              NaN              1.0   \n",
       "116320            NaN             NaN              NaN              NaN   \n",
       "126053            6.4             9.6              NaN              1.0   \n",
       "106054           -5.5             0.5              0.0              0.0   \n",
       "1644             10.0            14.3              0.2              0.0   \n",
       "5000             11.9            13.4              NaN              1.0   \n",
       "143003           11.0            17.5              0.0              0.0   \n",
       "139986            0.1             6.3              NaN              NaN   \n",
       "223699          -28.3           -15.5              NaN              NaN   \n",
       "161862          -12.6            -7.9              NaN              NaN   \n",
       "2454             10.0            13.3              2.8              0.0   \n",
       "9207              1.0             4.8              9.8              0.0   \n",
       "142024           -9.5            -5.0              0.0              0.0   \n",
       "11114             8.0            16.8              0.0              0.0   \n",
       "204931           -1.5             0.1              NaN              1.0   \n",
       "191677           10.4            12.9              NaN              1.0   \n",
       "33696             NaN             NaN              NaN              NaN   \n",
       "130519           10.5            15.8              0.0              0.0   \n",
       "180235            2.6             8.5              2.4              0.0   \n",
       "\n",
       "        Total Precip (mm)  Snow on Grnd (cm)  Dir of Max Gust (10s deg)  \\\n",
       "225431                0.2                NaN                        NaN   \n",
       "177962                0.0                NaN                        NaN   \n",
       "116320                NaN                NaN                        NaN   \n",
       "126053               19.5                NaN                        NaN   \n",
       "106054                0.0                0.0                        NaN   \n",
       "1644                  0.2                0.0                        NaN   \n",
       "5000                  0.2                NaN                       28.0   \n",
       "143003                0.0                0.0                        NaN   \n",
       "139986                4.7                NaN                       23.0   \n",
       "223699                0.2               46.0                        NaN   \n",
       "161862                0.0               34.0                       34.0   \n",
       "2454                  2.8                0.0                        NaN   \n",
       "9207                  9.8                0.0                        NaN   \n",
       "142024                0.0                6.0                        NaN   \n",
       "11114                 0.0                0.0                        NaN   \n",
       "204931                3.2                4.0                        NaN   \n",
       "191677                0.0                NaN                        1.0   \n",
       "33696                 NaN                NaN                        NaN   \n",
       "130519                0.0                0.0                        NaN   \n",
       "180235                2.4                NaN                        8.0   \n",
       "\n",
       "       Spd of Max Gust (km/h)  \n",
       "225431                    NaN  \n",
       "177962                    NaN  \n",
       "116320                    NaN  \n",
       "126053                    <31  \n",
       "106054                    NaN  \n",
       "1644                      NaN  \n",
       "5000                       52  \n",
       "143003                    NaN  \n",
       "139986                   50.0  \n",
       "223699                    NaN  \n",
       "161862                   39.0  \n",
       "2454                      NaN  \n",
       "9207                      NaN  \n",
       "142024                    NaN  \n",
       "11114                     NaN  \n",
       "204931                    <31  \n",
       "191677                     50  \n",
       "33696                     NaN  \n",
       "130519                    NaN  \n",
       "180235                     39  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>time</th>\n      <th>Station ID</th>\n      <th>avalanche_occured</th>\n      <th>Station Name</th>\n      <th>Climate ID_y</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Rain (mm)</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Precip (mm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>225431</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>POINT PELEE CS</td>\n      <td>613P001</td>\n      <td>2019</td>\n      <td>10</td>\n      <td>27</td>\n      <td>15.3</td>\n      <td>9.4</td>\n      <td>12.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>177962</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CAP-MADELEINE</td>\n      <td>7051163</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>17</td>\n      <td>11.1</td>\n      <td>1.6</td>\n      <td>6.4</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>116320</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CLEARWATER AUTO</td>\n      <td>1161650</td>\n      <td>2021</td>\n      <td>11</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>126053</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>REVELSTOKE A</td>\n      <td>1176745</td>\n      <td>2018</td>\n      <td>4</td>\n      <td>29</td>\n      <td>12.7</td>\n      <td>6.4</td>\n      <td>9.6</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>19.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>106054</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>KIMBERLEY PCC</td>\n      <td>1154203</td>\n      <td>2017</td>\n      <td>10</td>\n      <td>30</td>\n      <td>6.5</td>\n      <td>-5.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2020</td>\n      <td>7</td>\n      <td>2</td>\n      <td>18.5</td>\n      <td>10.0</td>\n      <td>14.3</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5000</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>FANNY ISLAND</td>\n      <td>1022795</td>\n      <td>2017</td>\n      <td>9</td>\n      <td>8</td>\n      <td>14.8</td>\n      <td>11.9</td>\n      <td>13.4</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>28.0</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>143003</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>PLEASANT CAMP</td>\n      <td>1206197</td>\n      <td>2016</td>\n      <td>8</td>\n      <td>27</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>17.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>139986</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>DEASE LAKE A</td>\n      <td>1192341</td>\n      <td>2020</td>\n      <td>5</td>\n      <td>25</td>\n      <td>12.4</td>\n      <td>0.1</td>\n      <td>6.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.7</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>223699</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>WILLOW CREEK 1</td>\n      <td>306GE70</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>29</td>\n      <td>-2.7</td>\n      <td>-28.3</td>\n      <td>-15.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.2</td>\n      <td>46.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>161862</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>JASPER WARDEN</td>\n      <td>3053536</td>\n      <td>2020</td>\n      <td>3</td>\n      <td>24</td>\n      <td>-3.2</td>\n      <td>-12.6</td>\n      <td>-7.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>34.0</td>\n      <td>34.0</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>2454</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>COURTENAY PUNTLEDGE</td>\n      <td>1021989</td>\n      <td>2016</td>\n      <td>9</td>\n      <td>19</td>\n      <td>16.5</td>\n      <td>10.0</td>\n      <td>13.3</td>\n      <td>2.8</td>\n      <td>0.0</td>\n      <td>2.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9207</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>QUINSAM RIVER HATCHERY</td>\n      <td>1026639</td>\n      <td>2017</td>\n      <td>3</td>\n      <td>12</td>\n      <td>8.5</td>\n      <td>1.0</td>\n      <td>4.8</td>\n      <td>9.8</td>\n      <td>0.0</td>\n      <td>9.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>142024</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>ATLIN</td>\n      <td>1200560</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>23</td>\n      <td>-0.5</td>\n      <td>-9.5</td>\n      <td>-5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11114</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>ALBERNI ROBERTSON CREEK</td>\n      <td>1030230</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>31</td>\n      <td>25.5</td>\n      <td>8.0</td>\n      <td>16.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>204931</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NELSON CS</td>\n      <td>1145M29</td>\n      <td>2018</td>\n      <td>1</td>\n      <td>23</td>\n      <td>1.7</td>\n      <td>-1.5</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n    </tr>\n    <tr>\n      <th>191677</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>HOWE SOUND - PAM ROCKS</td>\n      <td>10459NN</td>\n      <td>2017</td>\n      <td>10</td>\n      <td>28</td>\n      <td>15.4</td>\n      <td>10.4</td>\n      <td>12.9</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>33696</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>HOUSTON</td>\n      <td>1073615</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>130519</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CHETWYND A</td>\n      <td>1181508</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>28</td>\n      <td>21.0</td>\n      <td>10.5</td>\n      <td>15.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>180235</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>GASPE A</td>\n      <td>7052601</td>\n      <td>2016</td>\n      <td>7</td>\n      <td>7</td>\n      <td>14.3</td>\n      <td>2.6</td>\n      <td>8.5</td>\n      <td>2.4</td>\n      <td>0.0</td>\n      <td>2.4</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>39</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "new_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['temperature range'] = new_df['Max Temp (°C)'] - new_df['Min Temp (°C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Total Snow (cm)'].fillna(new_df['Total Precip (mm)'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_snow = new_df[(new_df['Total Snow (cm)'].isna())]\n",
    "\n",
    "new_df.dropna(subset = ['Total Snow (cm)'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 178674 entries, 0 to 228218\nData columns (total 21 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   latitude                   2011 non-null    object \n 1   longitude                  2011 non-null    object \n 2   weekday                    2011 non-null    object \n 3   time                       2011 non-null    object \n 4   Station ID                 2011 non-null    object \n 5   avalanche_occured          178674 non-null  float64\n 6   Station Name               178674 non-null  object \n 7   Climate ID_y               178674 non-null  object \n 8   Year                       178674 non-null  int64  \n 9   Month                      178674 non-null  int64  \n 10  Day                        178674 non-null  int64  \n 11  Max Temp (°C)              172694 non-null  float64\n 12  Min Temp (°C)              172148 non-null  float64\n 13  Mean Temp (°C)             170332 non-null  float64\n 14  Total Rain (mm)            91473 non-null   float64\n 15  Total Snow (cm)            178674 non-null  float64\n 16  Total Precip (mm)          170272 non-null  float64\n 17  Snow on Grnd (cm)          105544 non-null  float64\n 18  Dir of Max Gust (10s deg)  41067 non-null   float64\n 19  Spd of Max Gust (km/h)     66005 non-null   object \n 20  temperature range          171459 non-null  float64\ndtypes: float64(10), int64(3), object(8)\nmemory usage: 30.0+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        latitude   longitude    weekday   time Station ID  avalanche_occured  \\\n",
       "43522  52.877514  121.284415   Saturday  12:00        568                1.0   \n",
       "43523  52.726691  120.870898   Saturday  10:25        568                1.0   \n",
       "43524  53.135775  121.474432     Sunday  12:30        568                1.0   \n",
       "43544  52.610860  121.223630   Saturday  12:00        568                1.0   \n",
       "43571  52.721744  121.000059     Friday  12:30        568                1.0   \n",
       "43573  53.006580  121.510230     Sunday  13:40        568                1.0   \n",
       "43579  54.108740  121.411910   Saturday  20:48        568                1.0   \n",
       "43583  53.132270  121.454090  Wednesday  15:00        568                1.0   \n",
       "43586  52.608390  121.226670   Saturday  10:00        568                1.0   \n",
       "43594  52.765630  120.967530     Sunday  12:00        568                1.0   \n",
       "43597  52.948007  121.505411  Wednesday  10:30        568                1.0   \n",
       "43601  52.726660  121.020930     Sunday  14:00        568                1.0   \n",
       "43632  54.036625  121.229096  Wednesday  12:03        568                1.0   \n",
       "\n",
       "      Station Name Climate ID_y  Year  Month  ...  Max Temp (°C)  \\\n",
       "43522  BARKERVILLE      1090660  2020     12  ...            0.0   \n",
       "43523  BARKERVILLE      1090660  2020     12  ...            0.0   \n",
       "43524  BARKERVILLE      1090660  2020     12  ...           -1.0   \n",
       "43544  BARKERVILLE      1090660  2021      1  ...            0.0   \n",
       "43571  BARKERVILLE      1090660  2021      2  ...           -1.5   \n",
       "43573  BARKERVILLE      1090660  2021      2  ...          -12.5   \n",
       "43579  BARKERVILLE      1090660  2021      2  ...           -9.0   \n",
       "43583  BARKERVILLE      1090660  2021      2  ...           -5.0   \n",
       "43586  BARKERVILLE      1090660  2021      2  ...           -0.5   \n",
       "43594  BARKERVILLE      1090660  2021      2  ...            4.0   \n",
       "43597  BARKERVILLE      1090660  2021      3  ...            1.0   \n",
       "43601  BARKERVILLE      1090660  2021      3  ...            2.5   \n",
       "43632  BARKERVILLE      1090660  2021      4  ...            0.0   \n",
       "\n",
       "       Min Temp (°C)  Mean Temp (°C)  Total Rain (mm)  Total Snow (cm)  \\\n",
       "43522           -8.0            -4.0              0.0              7.0   \n",
       "43523           -8.0            -4.0              0.0              7.0   \n",
       "43524           -7.0            -4.0              0.0              3.0   \n",
       "43544          -12.5            -6.3              0.0              1.0   \n",
       "43571           -6.0            -3.8              0.0              8.0   \n",
       "43573          -23.5           -18.0              0.0              0.0   \n",
       "43579          -25.5           -17.3              0.0              0.0   \n",
       "43583          -18.0           -11.5              0.0              0.0   \n",
       "43586          -15.5            -8.0              0.0              8.0   \n",
       "43594           -7.0            -1.5              0.0              0.0   \n",
       "43597           -7.0            -3.0              0.0              0.0   \n",
       "43601           -6.5            -2.0              0.0              1.0   \n",
       "43632           -4.0            -2.0              2.0             16.0   \n",
       "\n",
       "       Total Precip (mm)  Snow on Grnd (cm)  Dir of Max Gust (10s deg)  \\\n",
       "43522                7.0               76.0                        NaN   \n",
       "43523                7.0               76.0                        NaN   \n",
       "43524                3.0               78.0                        NaN   \n",
       "43544                1.0               76.0                        NaN   \n",
       "43571                8.0              105.0                        NaN   \n",
       "43573                0.0              105.0                        NaN   \n",
       "43579                0.0              100.0                        NaN   \n",
       "43583                0.0              107.0                        NaN   \n",
       "43586                8.0              105.0                        NaN   \n",
       "43594                0.0              155.0                        NaN   \n",
       "43597                0.0              143.0                        NaN   \n",
       "43601                1.0                0.0                        NaN   \n",
       "43632               18.0              155.0                        NaN   \n",
       "\n",
       "       Spd of Max Gust (km/h) temperature range  \n",
       "43522                     NaN               8.0  \n",
       "43523                     NaN               8.0  \n",
       "43524                     NaN               6.0  \n",
       "43544                     NaN              12.5  \n",
       "43571                     NaN               4.5  \n",
       "43573                     NaN              11.0  \n",
       "43579                     NaN              16.5  \n",
       "43583                     NaN              13.0  \n",
       "43586                     NaN              15.0  \n",
       "43594                     NaN              11.0  \n",
       "43597                     NaN               8.0  \n",
       "43601                     NaN               9.0  \n",
       "43632                     NaN               4.0  \n",
       "\n",
       "[13 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>time</th>\n      <th>Station ID</th>\n      <th>avalanche_occured</th>\n      <th>Station Name</th>\n      <th>Climate ID_y</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>...</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Rain (mm)</th>\n      <th>Total Snow (cm)</th>\n      <th>Total Precip (mm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n      <th>temperature range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43522</th>\n      <td>52.877514</td>\n      <td>121.284415</td>\n      <td>Saturday</td>\n      <td>12:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-8.0</td>\n      <td>-4.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>43523</th>\n      <td>52.726691</td>\n      <td>120.870898</td>\n      <td>Saturday</td>\n      <td>10:25</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-8.0</td>\n      <td>-4.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>43524</th>\n      <td>53.135775</td>\n      <td>121.474432</td>\n      <td>Sunday</td>\n      <td>12:30</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-7.0</td>\n      <td>-4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>78.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>43544</th>\n      <td>52.610860</td>\n      <td>121.223630</td>\n      <td>Saturday</td>\n      <td>12:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-12.5</td>\n      <td>-6.3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>76.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.5</td>\n    </tr>\n    <tr>\n      <th>43571</th>\n      <td>52.721744</td>\n      <td>121.000059</td>\n      <td>Friday</td>\n      <td>12:30</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-1.5</td>\n      <td>-6.0</td>\n      <td>-3.8</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>105.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>43573</th>\n      <td>53.006580</td>\n      <td>121.510230</td>\n      <td>Sunday</td>\n      <td>13:40</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-12.5</td>\n      <td>-23.5</td>\n      <td>-18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>105.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>43579</th>\n      <td>54.108740</td>\n      <td>121.411910</td>\n      <td>Saturday</td>\n      <td>20:48</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-9.0</td>\n      <td>-25.5</td>\n      <td>-17.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.5</td>\n    </tr>\n    <tr>\n      <th>43583</th>\n      <td>53.132270</td>\n      <td>121.454090</td>\n      <td>Wednesday</td>\n      <td>15:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-5.0</td>\n      <td>-18.0</td>\n      <td>-11.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>107.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>43586</th>\n      <td>52.608390</td>\n      <td>121.226670</td>\n      <td>Saturday</td>\n      <td>10:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>-0.5</td>\n      <td>-15.5</td>\n      <td>-8.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>105.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>43594</th>\n      <td>52.765630</td>\n      <td>120.967530</td>\n      <td>Sunday</td>\n      <td>12:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>-7.0</td>\n      <td>-1.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>155.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>43597</th>\n      <td>52.948007</td>\n      <td>121.505411</td>\n      <td>Wednesday</td>\n      <td>10:30</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-7.0</td>\n      <td>-3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>143.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>43601</th>\n      <td>52.726660</td>\n      <td>121.020930</td>\n      <td>Sunday</td>\n      <td>14:00</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>-6.5</td>\n      <td>-2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>43632</th>\n      <td>54.036625</td>\n      <td>121.229096</td>\n      <td>Wednesday</td>\n      <td>12:03</td>\n      <td>568</td>\n      <td>1.0</td>\n      <td>BARKERVILLE</td>\n      <td>1090660</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-4.0</td>\n      <td>-2.0</td>\n      <td>2.0</td>\n      <td>16.0</td>\n      <td>18.0</td>\n      <td>155.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "new_df[new_df['Station ID'] == '568']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(['Total Rain (mm)','Total Precip (mm)'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       latitude longitude weekday time Station ID  avalanche_occured  \\\n",
       "38645       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "93316       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "219332      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "175317      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "119614      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "146951      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "106505      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "426         NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "12113       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "102211      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "59580       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "140171      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "17006       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "172409      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "199533      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "22611       NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "188560      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "190304      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "178592      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "176497      NaN       NaN     NaN  NaN        NaN                0.0   \n",
       "\n",
       "                    Station Name Climate ID_y  Year  Month  Day  \\\n",
       "38645      SMITHERS AIRPORT AUTO      1077501  2019      9   26   \n",
       "93316                 NEW DENVER      1145460  2019      1   19   \n",
       "219332                 CROWSNEST      3051R4R  2021      3    2   \n",
       "175317                ARTHABASKA      7020305  2021      1   20   \n",
       "119614                   VAVENBY      1168520  2018     11   30   \n",
       "146951              WHITEHORSE A      2101303  2021      6    8   \n",
       "106505             KIMBERLEY PCC      1154203  2019      1   24   \n",
       "426             CAMPBELL RIVER A      1021261  2017      3    2   \n",
       "12113    ALBERNI ROBERTSON CREEK      1030230  2019      2   24   \n",
       "102211                    FERNIE      1152850  2019      5   18   \n",
       "59580   N VANC GROUSE MTN RESORT      1105658  2016     11   21   \n",
       "140171              DEASE LAKE A      1192341  2020     11   26   \n",
       "17006                   TOFINO A      1038205  2020      7   15   \n",
       "172409           BEAVERLODGE RCS      3070600  2019      2    4   \n",
       "199533             SUSKWA VALLEY      107G879  2021      4   23   \n",
       "22611                PORT MELLON      1046332  2017     11   17   \n",
       "188560         ST. JOHN'S INTL A      8403505  2021      4   17   \n",
       "190304                  WABUSH A      8504177  2020      1   25   \n",
       "178592             CAP-MADELEINE      7051163  2018      1    7   \n",
       "176497                  MCTAVISH      7024745  2018      4   14   \n",
       "\n",
       "        Max Temp (°C)  Min Temp (°C)  Mean Temp (°C)  Total Snow (cm)  \\\n",
       "38645            11.1            0.3             5.7              0.6   \n",
       "93316             4.0            0.5             2.3              0.0   \n",
       "219332            4.5            2.6             3.5              0.0   \n",
       "175317           -7.0          -14.0             NaN              4.4   \n",
       "119614            1.0           -0.5             0.3              0.0   \n",
       "146951           21.3            2.8            12.1              1.0   \n",
       "106505            1.0           -9.5            -4.3              0.0   \n",
       "426               8.0            2.0             5.0              0.0   \n",
       "12113             9.0            0.0             4.5              0.0   \n",
       "102211            9.0            5.0             7.0              0.0   \n",
       "59580             3.0            1.5             2.3              0.0   \n",
       "140171            0.1           -8.5            -4.2              0.0   \n",
       "17006            20.0           12.5            16.3              0.0   \n",
       "172409          -29.3          -41.3           -35.3              0.3   \n",
       "199533           16.0           -3.5             6.3              0.0   \n",
       "22611             6.0            0.7             3.4              1.0   \n",
       "188560            4.0           -0.5             1.8              0.0   \n",
       "190304           -8.3          -21.0           -14.7              0.0   \n",
       "178592          -11.2          -18.0           -14.6              1.0   \n",
       "176497            6.6           -3.8             1.4              1.0   \n",
       "\n",
       "        Snow on Grnd (cm)  Dir of Max Gust (10s deg) Spd of Max Gust (km/h)  \\\n",
       "38645                 NaN                        NaN                    NaN   \n",
       "93316                 8.0                        NaN                    NaN   \n",
       "219332                NaN                       29.0                   71.0   \n",
       "175317               28.0                        NaN                    NaN   \n",
       "119614                0.0                        NaN                    NaN   \n",
       "146951                NaN                       23.0                   44.0   \n",
       "106505               11.0                        NaN                    NaN   \n",
       "426                   0.0                        NaN                    NaN   \n",
       "12113                 3.0                        NaN                    NaN   \n",
       "102211                0.0                        NaN                    NaN   \n",
       "59580                 0.0                        NaN                    NaN   \n",
       "140171                NaN                       21.0                   41.0   \n",
       "17006                 0.0                        NaN                    NaN   \n",
       "172409               18.0                        NaN                    NaN   \n",
       "199533                0.0                        NaN                    NaN   \n",
       "22611                 NaN                        NaN                    <31   \n",
       "188560                NaN                        6.0                   55.0   \n",
       "190304                NaN                        NaN                    NaN   \n",
       "178592               10.0                       21.0                     85   \n",
       "176497                4.0                        2.0                     33   \n",
       "\n",
       "        temperature range  \n",
       "38645                10.8  \n",
       "93316                 3.5  \n",
       "219332                1.9  \n",
       "175317                7.0  \n",
       "119614                1.5  \n",
       "146951               18.5  \n",
       "106505               10.5  \n",
       "426                   6.0  \n",
       "12113                 9.0  \n",
       "102211                4.0  \n",
       "59580                 1.5  \n",
       "140171                8.6  \n",
       "17006                 7.5  \n",
       "172409               12.0  \n",
       "199533               19.5  \n",
       "22611                 5.3  \n",
       "188560                4.5  \n",
       "190304               12.7  \n",
       "178592                6.8  \n",
       "176497               10.4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>time</th>\n      <th>Station ID</th>\n      <th>avalanche_occured</th>\n      <th>Station Name</th>\n      <th>Climate ID_y</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Snow (cm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n      <th>temperature range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38645</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>SMITHERS AIRPORT AUTO</td>\n      <td>1077501</td>\n      <td>2019</td>\n      <td>9</td>\n      <td>26</td>\n      <td>11.1</td>\n      <td>0.3</td>\n      <td>5.7</td>\n      <td>0.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.8</td>\n    </tr>\n    <tr>\n      <th>93316</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NEW DENVER</td>\n      <td>1145460</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>19</td>\n      <td>4.0</td>\n      <td>0.5</td>\n      <td>2.3</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>219332</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CROWSNEST</td>\n      <td>3051R4R</td>\n      <td>2021</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4.5</td>\n      <td>2.6</td>\n      <td>3.5</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>29.0</td>\n      <td>71.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>175317</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>ARTHABASKA</td>\n      <td>7020305</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>20</td>\n      <td>-7.0</td>\n      <td>-14.0</td>\n      <td>NaN</td>\n      <td>4.4</td>\n      <td>28.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>119614</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>VAVENBY</td>\n      <td>1168520</td>\n      <td>2018</td>\n      <td>11</td>\n      <td>30</td>\n      <td>1.0</td>\n      <td>-0.5</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>146951</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>WHITEHORSE A</td>\n      <td>2101303</td>\n      <td>2021</td>\n      <td>6</td>\n      <td>8</td>\n      <td>21.3</td>\n      <td>2.8</td>\n      <td>12.1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>44.0</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>106505</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>KIMBERLEY PCC</td>\n      <td>1154203</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>24</td>\n      <td>1.0</td>\n      <td>-9.5</td>\n      <td>-4.3</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>426</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CAMPBELL RIVER A</td>\n      <td>1021261</td>\n      <td>2017</td>\n      <td>3</td>\n      <td>2</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>12113</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>ALBERNI ROBERTSON CREEK</td>\n      <td>1030230</td>\n      <td>2019</td>\n      <td>2</td>\n      <td>24</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>4.5</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>102211</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>FERNIE</td>\n      <td>1152850</td>\n      <td>2019</td>\n      <td>5</td>\n      <td>18</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>59580</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>N VANC GROUSE MTN RESORT</td>\n      <td>1105658</td>\n      <td>2016</td>\n      <td>11</td>\n      <td>21</td>\n      <td>3.0</td>\n      <td>1.5</td>\n      <td>2.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>140171</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>DEASE LAKE A</td>\n      <td>1192341</td>\n      <td>2020</td>\n      <td>11</td>\n      <td>26</td>\n      <td>0.1</td>\n      <td>-8.5</td>\n      <td>-4.2</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>41.0</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>17006</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>TOFINO A</td>\n      <td>1038205</td>\n      <td>2020</td>\n      <td>7</td>\n      <td>15</td>\n      <td>20.0</td>\n      <td>12.5</td>\n      <td>16.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>172409</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>BEAVERLODGE RCS</td>\n      <td>3070600</td>\n      <td>2019</td>\n      <td>2</td>\n      <td>4</td>\n      <td>-29.3</td>\n      <td>-41.3</td>\n      <td>-35.3</td>\n      <td>0.3</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>199533</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>SUSKWA VALLEY</td>\n      <td>107G879</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>23</td>\n      <td>16.0</td>\n      <td>-3.5</td>\n      <td>6.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>22611</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>PORT MELLON</td>\n      <td>1046332</td>\n      <td>2017</td>\n      <td>11</td>\n      <td>17</td>\n      <td>6.0</td>\n      <td>0.7</td>\n      <td>3.4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>5.3</td>\n    </tr>\n    <tr>\n      <th>188560</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>ST. JOHN'S INTL A</td>\n      <td>8403505</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>17</td>\n      <td>4.0</td>\n      <td>-0.5</td>\n      <td>1.8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>55.0</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>190304</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>WABUSH A</td>\n      <td>8504177</td>\n      <td>2020</td>\n      <td>1</td>\n      <td>25</td>\n      <td>-8.3</td>\n      <td>-21.0</td>\n      <td>-14.7</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.7</td>\n    </tr>\n    <tr>\n      <th>178592</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CAP-MADELEINE</td>\n      <td>7051163</td>\n      <td>2018</td>\n      <td>1</td>\n      <td>7</td>\n      <td>-11.2</td>\n      <td>-18.0</td>\n      <td>-14.6</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>21.0</td>\n      <td>85</td>\n      <td>6.8</td>\n    </tr>\n    <tr>\n      <th>176497</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>MCTAVISH</td>\n      <td>7024745</td>\n      <td>2018</td>\n      <td>4</td>\n      <td>14</td>\n      <td>6.6</td>\n      <td>-3.8</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>33</td>\n      <td>10.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "new_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_df = new_df.groupby('avalanche_occured').apply(lambda x: x.sample(n=2011)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       latitude   longitude weekday   time Station ID  avalanche_occured  \\\n",
       "0           NaN         NaN     NaN    NaN        NaN                0.0   \n",
       "1           NaN         NaN     NaN    NaN        NaN                0.0   \n",
       "2           NaN         NaN     NaN    NaN        NaN                0.0   \n",
       "3           NaN         NaN     NaN    NaN        NaN                0.0   \n",
       "4           NaN         NaN     NaN    NaN        NaN                0.0   \n",
       "...         ...         ...     ...    ...        ...                ...   \n",
       "4017  49.471683  124.974924  Sunday  13:30        225                1.0   \n",
       "4018  51.276221  117.096621  Monday  17:24       1364                1.0   \n",
       "4019  50.406700  122.434130  Friday  12:00        536                1.0   \n",
       "4020  49.427499  117.285401  Sunday  10:30       6839                1.0   \n",
       "4021  51.312630  115.938470  Friday  12:00      27378                1.0   \n",
       "\n",
       "                 Station Name Climate ID_y  Year  Month  Day  Max Temp (°C)  \\\n",
       "0              DAWSON CREEK A      1182289  2017     12    4            4.4   \n",
       "1                BLUE RIVER A      1160899  2021      3    9            8.0   \n",
       "2                   NELSON CS      1145M29  2018      4   11           12.5   \n",
       "3                   CROWSNEST      3051R4R  2017      5   24           18.5   \n",
       "4                  BOW VALLEY      3050778  2017     12   19           -6.6   \n",
       "...                       ...          ...   ...    ...  ...            ...   \n",
       "4017  ALBERNI ROBERTSON CREEK      1030230  2021      1   31            5.0   \n",
       "4018                 GOLDEN A      1173210  2019      1   28           -4.0   \n",
       "4019     PEMBERTON AIRPORT CS      1086082  2021      2   26            9.8   \n",
       "4020                NELSON CS      1145M29  2021      1   31            3.4   \n",
       "4021                 BANFF CS      3050519  2020      2   28            6.4   \n",
       "\n",
       "      Min Temp (°C)  Mean Temp (°C)  Total Snow (cm)  Snow on Grnd (cm)  \\\n",
       "0              -4.1             0.2              1.0                NaN   \n",
       "1             -12.5            -2.3              0.0               68.0   \n",
       "2               4.4             8.5              1.0                NaN   \n",
       "3               4.0            11.3              1.0                NaN   \n",
       "4             -11.5            -9.1              1.0                NaN   \n",
       "...             ...             ...              ...                ...   \n",
       "4017            2.0             3.5              0.0                0.0   \n",
       "4018          -13.5            -8.8              0.0               26.0   \n",
       "4019           -1.2             4.3              0.0               20.0   \n",
       "4020            1.1             2.3              4.7                4.0   \n",
       "4021            0.9             3.7              0.0               38.0   \n",
       "\n",
       "      Dir of Max Gust (10s deg) Spd of Max Gust (km/h)  temperature range  \n",
       "0                          26.0                     61                8.5  \n",
       "1                           NaN                    NaN               20.5  \n",
       "2                           NaN                    <31                8.1  \n",
       "3                          29.0                     74               14.5  \n",
       "4                           NaN                    <31                4.9  \n",
       "...                         ...                    ...                ...  \n",
       "4017                        NaN                    NaN                3.0  \n",
       "4018                        NaN                    NaN                9.5  \n",
       "4019                        NaN                    NaN               11.0  \n",
       "4020                        NaN                    NaN                2.3  \n",
       "4021                       21.0                   39.0                5.5  \n",
       "\n",
       "[4022 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>weekday</th>\n      <th>time</th>\n      <th>Station ID</th>\n      <th>avalanche_occured</th>\n      <th>Station Name</th>\n      <th>Climate ID_y</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Snow (cm)</th>\n      <th>Snow on Grnd (cm)</th>\n      <th>Dir of Max Gust (10s deg)</th>\n      <th>Spd of Max Gust (km/h)</th>\n      <th>temperature range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>DAWSON CREEK A</td>\n      <td>1182289</td>\n      <td>2017</td>\n      <td>12</td>\n      <td>4</td>\n      <td>4.4</td>\n      <td>-4.1</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>61</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>BLUE RIVER A</td>\n      <td>1160899</td>\n      <td>2021</td>\n      <td>3</td>\n      <td>9</td>\n      <td>8.0</td>\n      <td>-12.5</td>\n      <td>-2.3</td>\n      <td>0.0</td>\n      <td>68.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NELSON CS</td>\n      <td>1145M29</td>\n      <td>2018</td>\n      <td>4</td>\n      <td>11</td>\n      <td>12.5</td>\n      <td>4.4</td>\n      <td>8.5</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>8.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>CROWSNEST</td>\n      <td>3051R4R</td>\n      <td>2017</td>\n      <td>5</td>\n      <td>24</td>\n      <td>18.5</td>\n      <td>4.0</td>\n      <td>11.3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>29.0</td>\n      <td>74</td>\n      <td>14.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>BOW VALLEY</td>\n      <td>3050778</td>\n      <td>2017</td>\n      <td>12</td>\n      <td>19</td>\n      <td>-6.6</td>\n      <td>-11.5</td>\n      <td>-9.1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>&lt;31</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4017</th>\n      <td>49.471683</td>\n      <td>124.974924</td>\n      <td>Sunday</td>\n      <td>13:30</td>\n      <td>225</td>\n      <td>1.0</td>\n      <td>ALBERNI ROBERTSON CREEK</td>\n      <td>1030230</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>31</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4018</th>\n      <td>51.276221</td>\n      <td>117.096621</td>\n      <td>Monday</td>\n      <td>17:24</td>\n      <td>1364</td>\n      <td>1.0</td>\n      <td>GOLDEN A</td>\n      <td>1173210</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>28</td>\n      <td>-4.0</td>\n      <td>-13.5</td>\n      <td>-8.8</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>4019</th>\n      <td>50.406700</td>\n      <td>122.434130</td>\n      <td>Friday</td>\n      <td>12:00</td>\n      <td>536</td>\n      <td>1.0</td>\n      <td>PEMBERTON AIRPORT CS</td>\n      <td>1086082</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>26</td>\n      <td>9.8</td>\n      <td>-1.2</td>\n      <td>4.3</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>4020</th>\n      <td>49.427499</td>\n      <td>117.285401</td>\n      <td>Sunday</td>\n      <td>10:30</td>\n      <td>6839</td>\n      <td>1.0</td>\n      <td>NELSON CS</td>\n      <td>1145M29</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>31</td>\n      <td>3.4</td>\n      <td>1.1</td>\n      <td>2.3</td>\n      <td>4.7</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>4021</th>\n      <td>51.312630</td>\n      <td>115.938470</td>\n      <td>Friday</td>\n      <td>12:00</td>\n      <td>27378</td>\n      <td>1.0</td>\n      <td>BANFF CS</td>\n      <td>3050519</td>\n      <td>2020</td>\n      <td>2</td>\n      <td>28</td>\n      <td>6.4</td>\n      <td>0.9</td>\n      <td>3.7</td>\n      <td>0.0</td>\n      <td>38.0</td>\n      <td>21.0</td>\n      <td>39.0</td>\n      <td>5.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>4022 rows × 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "incident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4022 entries, 0 to 4021\nData columns (total 19 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   latitude                   2011 non-null   object \n 1   longitude                  2011 non-null   object \n 2   weekday                    2011 non-null   object \n 3   time                       2011 non-null   object \n 4   Station ID                 2011 non-null   object \n 5   avalanche_occured          4022 non-null   float64\n 6   Station Name               4022 non-null   object \n 7   Climate ID_y               4022 non-null   object \n 8   Year                       4022 non-null   int64  \n 9   Month                      4022 non-null   int64  \n 10  Day                        4022 non-null   int64  \n 11  Max Temp (°C)              3946 non-null   float64\n 12  Min Temp (°C)              3954 non-null   float64\n 13  Mean Temp (°C)             3927 non-null   float64\n 14  Total Snow (cm)            4022 non-null   float64\n 15  Snow on Grnd (cm)          2791 non-null   float64\n 16  Dir of Max Gust (10s deg)  905 non-null    float64\n 17  Spd of Max Gust (km/h)     1283 non-null   object \n 18  temperature range          3937 non-null   float64\ndtypes: float64(8), int64(3), object(8)\nmemory usage: 597.1+ KB\n"
     ]
    }
   ],
   "source": [
    "incident_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_df.drop(['Dir of Max Gust (10s deg)','Spd of Max Gust (km/h)','Snow on Grnd (cm)'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4022 entries, 0 to 4021\nData columns (total 16 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   latitude           2011 non-null   object \n 1   longitude          2011 non-null   object \n 2   weekday            2011 non-null   object \n 3   time               2011 non-null   object \n 4   Station ID         2011 non-null   object \n 5   avalanche_occured  4022 non-null   float64\n 6   Station Name       4022 non-null   object \n 7   Climate ID_y       4022 non-null   object \n 8   Year               4022 non-null   int64  \n 9   Month              4022 non-null   int64  \n 10  Day                4022 non-null   int64  \n 11  Max Temp (°C)      3946 non-null   float64\n 12  Min Temp (°C)      3954 non-null   float64\n 13  Mean Temp (°C)     3927 non-null   float64\n 14  Total Snow (cm)    4022 non-null   float64\n 15  temperature range  3937 non-null   float64\ndtypes: float64(6), int64(3), object(7)\nmemory usage: 502.9+ KB\n"
     ]
    }
   ],
   "source": [
    "incident_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_df.drop(['latitude','longitude','weekday','time','Station ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_df.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3927 entries, 0 to 4021\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   avalanche_occured  3927 non-null   float64\n 1   Station Name       3927 non-null   object \n 2   Climate ID_y       3927 non-null   object \n 3   Year               3927 non-null   int64  \n 4   Month              3927 non-null   int64  \n 5   Day                3927 non-null   int64  \n 6   Max Temp (°C)      3927 non-null   float64\n 7   Min Temp (°C)      3927 non-null   float64\n 8   Mean Temp (°C)     3927 non-null   float64\n 9   Total Snow (cm)    3927 non-null   float64\n 10  temperature range  3927 non-null   float64\ndtypes: float64(6), int64(3), object(2)\nmemory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "incident_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = incident_df['avalanche_occured']\n",
    "X = incident_df.drop(['avalanche_occured','Station Name','Climate ID_y','Year','Month','Day'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Max Temp (°C)  Min Temp (°C)  Mean Temp (°C)  Total Snow (cm)  \\\n",
       "0            4.4           -4.1             0.2              1.0   \n",
       "1            8.0          -12.5            -2.3              0.0   \n",
       "2           12.5            4.4             8.5              1.0   \n",
       "3           18.5            4.0            11.3              1.0   \n",
       "4           -6.6          -11.5            -9.1              1.0   \n",
       "\n",
       "   temperature range  \n",
       "0                8.5  \n",
       "1               20.5  \n",
       "2                8.1  \n",
       "3               14.5  \n",
       "4                4.9  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Snow (cm)</th>\n      <th>temperature range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.4</td>\n      <td>-4.1</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.0</td>\n      <td>-12.5</td>\n      <td>-2.3</td>\n      <td>0.0</td>\n      <td>20.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.5</td>\n      <td>4.4</td>\n      <td>8.5</td>\n      <td>1.0</td>\n      <td>8.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.5</td>\n      <td>4.0</td>\n      <td>11.3</td>\n      <td>1.0</td>\n      <td>14.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.6</td>\n      <td>-11.5</td>\n      <td>-9.1</td>\n      <td>1.0</td>\n      <td>4.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 187
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 191
    }
   ],
   "source": [
    "my_logreg = LogisticRegression(C = 0.1,random_state=1)\n",
    "my_logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7357529449219994\n0.7175572519083969\n"
     ]
    }
   ],
   "source": [
    "print(my_logreg.score(X_train,y_train))\n",
    "print(my_logreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the series of steps we're using\n",
    "\n",
    "pipe_estimators = [('scaling', StandardScaler()),\n",
    "                   ('classifier', DecisionTreeClassifier())]\n",
    "\n",
    "avalanche_pipe = Pipeline(pipe_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=2, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=2, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             param_grid=[{'classifier': [SVC(C=10)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'scaling': [None, StandardScaler(), MinMaxScaler()]},\n",
       "                         {'classifier': [DecisionTreeClassifier()],\n",
       "                          'classifier__max_depth': [2, 3, 4, 5, 6, 7],\n",
       "                          'scaling': [None, MinMaxScaler()]},\n",
       "                         {'classifier': [KNeighborsClassifier()],\n",
       "                          'classifier__n_neighbors': [6, 10, 16, 17],\n",
       "                          'scaling': [StandardScaler(), MinMaxScaler(), None]},\n",
       "                         {'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'scaling': [None, StandardScaler(), MinMaxScaler()]}],\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "source": [
    "# SVMs, DTs, KNNs\n",
    "\n",
    "logit_gird = {'classifier': [LogisticRegression()],\n",
    "              'scaling': [None, StandardScaler(),MinMaxScaler()],\n",
    "              'classifier__C': [10**i for i in range(-2, 3)]}\n",
    "\n",
    "svm_grid = {'classifier': [SVC(C=1)],\n",
    "            'scaling': [None, StandardScaler(),MinMaxScaler()],\n",
    "            'classifier__C': [10**i for i in range(-2, 3)]}\n",
    "\n",
    "\n",
    "DT_grid = {'classifier': [DecisionTreeClassifier()],\n",
    "            'scaling': [None, MinMaxScaler()],\n",
    "            'classifier__max_depth': [2,3,4,5,6,7]}\n",
    "\n",
    "\n",
    "KNN_grid = {'classifier': [KNeighborsClassifier()],\n",
    "            'scaling': [StandardScaler(), MinMaxScaler(), None],\n",
    "            'classifier__n_neighbors': [6, 10, 16, 17]}\n",
    "\n",
    "\n",
    "param_grid = [svm_grid, \n",
    "              DT_grid,\n",
    "              KNN_grid,\n",
    "              logit_gird]\n",
    "\n",
    "\n",
    "\n",
    "avalanche_gridsearch = GridSearchCV(breast_cancer_pipe, param_grid=param_grid, cv=5, verbose=2)\n",
    "avalanche_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaling', None), ('classifier', SVC(C=10))])"
      ]
     },
     "metadata": {},
     "execution_count": 251
    }
   ],
   "source": [
    "avalanche_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7545367717287488\n0.7442748091603053\n"
     ]
    }
   ],
   "source": [
    "print(avalanche_gridsearch.best_estimator_.score(X_train, y_train))\n",
    "print(avalanche_gridsearch.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(arg):\n",
    "    if arg['Min Temp (°C)'] < 0 and arg['Max Temp (°C)'] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Freeze Thaw'] = X.apply(condition, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Max Temp (°C)  Min Temp (°C)  Mean Temp (°C)  Total Snow (cm)  \\\n",
       "0               4.4           -4.1             0.2              1.0   \n",
       "1               8.0          -12.5            -2.3              0.0   \n",
       "2              12.5            4.4             8.5              1.0   \n",
       "3              18.5            4.0            11.3              1.0   \n",
       "4              -6.6          -11.5            -9.1              1.0   \n",
       "...             ...            ...             ...              ...   \n",
       "4017            5.0            2.0             3.5              0.0   \n",
       "4018           -4.0          -13.5            -8.8              0.0   \n",
       "4019            9.8           -1.2             4.3              0.0   \n",
       "4020            3.4            1.1             2.3              4.7   \n",
       "4021            6.4            0.9             3.7              0.0   \n",
       "\n",
       "      temperature range  Freeze Thaw  \n",
       "0                   8.5            1  \n",
       "1                  20.5            1  \n",
       "2                   8.1            0  \n",
       "3                  14.5            0  \n",
       "4                   4.9            0  \n",
       "...                 ...          ...  \n",
       "4017                3.0            0  \n",
       "4018                9.5            0  \n",
       "4019               11.0            1  \n",
       "4020                2.3            0  \n",
       "4021                5.5            0  \n",
       "\n",
       "[3927 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max Temp (°C)</th>\n      <th>Min Temp (°C)</th>\n      <th>Mean Temp (°C)</th>\n      <th>Total Snow (cm)</th>\n      <th>temperature range</th>\n      <th>Freeze Thaw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.4</td>\n      <td>-4.1</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>8.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.0</td>\n      <td>-12.5</td>\n      <td>-2.3</td>\n      <td>0.0</td>\n      <td>20.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.5</td>\n      <td>4.4</td>\n      <td>8.5</td>\n      <td>1.0</td>\n      <td>8.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.5</td>\n      <td>4.0</td>\n      <td>11.3</td>\n      <td>1.0</td>\n      <td>14.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.6</td>\n      <td>-11.5</td>\n      <td>-9.1</td>\n      <td>1.0</td>\n      <td>4.9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4017</th>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4018</th>\n      <td>-4.0</td>\n      <td>-13.5</td>\n      <td>-8.8</td>\n      <td>0.0</td>\n      <td>9.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4019</th>\n      <td>9.8</td>\n      <td>-1.2</td>\n      <td>4.3</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4020</th>\n      <td>3.4</td>\n      <td>1.1</td>\n      <td>2.3</td>\n      <td>4.7</td>\n      <td>2.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4021</th>\n      <td>6.4</td>\n      <td>0.9</td>\n      <td>3.7</td>\n      <td>0.0</td>\n      <td>5.5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3927 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 240
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=2, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=2, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=3, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=4, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=5, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=DecisionTreeClassifier(), classifier__max_depth=7, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=6, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=16, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=KNeighborsClassifier(), classifier__n_neighbors=17, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.01, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=0.1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=1, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=10, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=None; total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=StandardScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n",
      "[CV] END classifier=LogisticRegression(), classifier__C=100, scaling=MinMaxScaler(); total time=   0.0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             param_grid=[{'classifier': [SVC(C=10)],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'scaling': [None, StandardScaler(), MinMaxScaler()]},\n",
       "                         {'classifier': [DecisionTreeClassifier()],\n",
       "                          'classifier__max_depth': [2, 3, 4, 5, 6, 7],\n",
       "                          'scaling': [None, MinMaxScaler()]},\n",
       "                         {'classifier': [KNeighborsClassifier()],\n",
       "                          'classifier__n_neighbors': [6, 10, 16, 17],\n",
       "                          'scaling': [StandardScaler(), MinMaxScaler(), None]},\n",
       "                         {'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                          'scaling': [None, StandardScaler(), MinMaxScaler()]}],\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "avalanche_gridsearch2 = GridSearchCV(breast_cancer_pipe, param_grid=param_grid, cv=5, verbose=2)\n",
    "avalanche_gridsearch2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaling', None), ('classifier', SVC(C=10))])"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "avalanche_gridsearch2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7545367717287488\n0.7442748091603053\n"
     ]
    }
   ],
   "source": [
    "print(avalanche_gridsearch2.best_estimator_.score(X_train, y_train))\n",
    "print(avalanche_gridsearch2.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "42c333185575f155416f495c198c86d87f9e670460b875bf5303d0b7fb1f6d34"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}