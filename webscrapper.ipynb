{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libraries\n",
    "from typing import Text\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import selenium libraries\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common import keys\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the path for the chrome driver\n",
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "\n",
    "# Initializes the driver\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# Opens a webpage on the driver\n",
    "driver.get('https://www.avalanche.ca/mountain-information-network/submissions')\n",
    "# Print out the title of the website\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens the down drop container for the 'Report Type'\n",
    "dropdown = driver.find_element_by_class_name('Dropdown_Container__2ZbXz')\n",
    "dropdown.click()\n",
    "\n",
    "# Finds the the avalanche option and clicks it\n",
    "driver.find_element_by_xpath('//div[@title=\"Avalanche\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the beginning date range box as datebox and clicks it\n",
    "datebox = driver.find_element_by_class_name('DayPickerInput')\n",
    "datebox.click()\n",
    "\n",
    "# Defines the previous month button and clicks it\n",
    "date_change_button = driver.find_element_by_xpath(\"//div[@class='DayPicker-NavBar']/span[@class='DayPicker-NavButton DayPicker-NavButton--prev']\")\n",
    "date_change_button.click()\n",
    "\n",
    "# Defines the read out of the date\n",
    "datebox_month =  driver.find_element_by_class_name(\"DayPicker-Caption\").text\n",
    "\n",
    "# Creates a loop that checks if the date equals Februrary 2016\n",
    "# If the month is not equal it clicks the previous month button and sets the current month to the new month\n",
    "while datebox_month != 'FEBRUARY 2016':\n",
    "    new_datebox_month =  driver.find_element_by_class_name(\"DayPicker-Caption\").text\n",
    "    date_change_button.click()\n",
    "    datebox_month = new_datebox_month\n",
    "\n",
    "# Once the correct month is found selenium clicks on the first of the month   \n",
    "select_date_button = driver.find_element_by_xpath(\"//div[@class='DayPicker-Week']/div[@aria-label='Friday, January 1, 2016']\")\n",
    "select_date_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of pages that selenium will check\n",
    "pages = range(2,51)\n",
    "list_pages = list(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store URLs\n",
    "report_url_list = []\n",
    "# Sets the time out delay for the website to load\n",
    "delay = 30\n",
    "\n",
    "# Iterates through each page of results, waits for the page to loads, records all the urls to incidents\n",
    "for i in list_pages:\n",
    "    \n",
    "    # Create a condition that waits for the reports the load before proceeding \n",
    "    try:\n",
    "        myElem = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div/div/div/div/div/div/div/main/div[2]/table/tbody/tr[1]')))\n",
    "\n",
    "        # Finds all elements that have a submission URL in them and creates a list\n",
    "        reports = driver.find_elements_by_xpath(\"//a[contains(@href, '/map?panel=mountain-information-network-submissions/')]\")\n",
    "\n",
    "        # Iterates through all the reports and gets their urls\n",
    "        for report in reports:\n",
    "            report_url_list.append(report.get_attribute('href'))\n",
    "\n",
    "        # Once all the reports and been iterated though goes to the next page\n",
    "        driver.find_element_by_xpath(\"//div[@class='Pagination_Container__2Z9O-']/button[contains(text(), '\"+str(i)+\"')]\").click()\n",
    "        num_of_urls = len(set(report_url_list))\n",
    "\n",
    "    # Executes except if page does not load in the 'delay' amount of time \n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the number of unique results\n",
    "\n",
    "len(set(report_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the number of results\n",
    "\n",
    "print(len(report_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the list of URLs to a DataFrame for readability\n",
    "\n",
    "incident_links = pd.DataFrame({'links':report_url_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the URLs as a csv without an index\n",
    "# The purpose of this is to allow the kernal to be restarted without losing all progress\n",
    "\n",
    "incident_links.to_csv('avanlanche_links.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in the links if needed\n",
    "\n",
    "avalanche_links_df = pd.read_csv('avanlanche_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of from the URL DataFrame\n",
    "\n",
    "test_avalanche = avalanche_links_df['links'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializes a empty lift for the avalanche location and time of occurance\n",
    "avalanche_location_time = list()\n",
    "\n",
    "# Opens a new webdriver using chrome\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# Iterates through all the links to the avalanche reports\n",
    "for link in test_avalanche:\n",
    "\n",
    "    try:\n",
    "        # Navigates selenium to the current page in the list\n",
    "        driver.get(link)\n",
    "\n",
    "        # Waits for the page to load the data\n",
    "        myElem = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='root']/div/div/div/main/section[2]/div/div[2]/dl/div[3]/dd\")))\n",
    "\n",
    "        # Collects the location data from the report\n",
    "        location = driver.find_element_by_xpath(\"//*[@id='root']/div/div/div/main/section[2]/div/div[2]/dl/div[3]/dd\").get_attribute('innerHTML')\n",
    "\n",
    "        # Collects the time of occurance from the report\n",
    "        time_occured = driver.find_element_by_xpath(\"//*[@id='root']/div/div/div/main/section[2]/div/div[2]/dl/div[2]/dd\").get_attribute('innerHTML')\n",
    "\n",
    "        # Creates a list of dictionaries to store the data\n",
    "        avalanche_location_time.append({'location':location,'date_occured':time_occured})\n",
    "        \n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time!\")\n",
    "\n",
    "# Converts the information to a DataFrame\n",
    "avalanche_df = pd.DataFrame(avalanche_location_time)\n",
    "\n",
    "# Saves the information as a csv with an index \n",
    "avalanche_df.to_csv('avalanche.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python385jvsc74a57bd0937229e3b8cc234f45d1b83f259b22cb5a2a2997d0f15f5055a6695ba05997b0",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}